<div class="ribbon">&nbsp;</div>

# Publications by Year
[[Google Scholar](https://scholar.google.com/citations?user=XcQ9WqMAAAAJ)]
[[dblp](https://dblp.org/pers/hd/r/Ren:Mengye)]

----------------------------------------------------------------------------

## Preprints

* <span class='paper-title'>[Integrating present and past in unsupervised continual learning](https://arxiv.org/abs/2404.19132).</span>
Yipeng Zhang, Laurent Charlin, Richard Zemel, Mengye Ren.
*arXiv preprint 2404.19132*, 2024.
[[arxiv](https://arxiv.org/abs/2404.19132)]

* <span class='paper-title'>[CoLLEGe: Concept embedding generation for large language models](https://arxiv.org/abs/2403.15362).</span>
Ryan Teehan, Brenden M. Lake, Mengye Ren.
*arXiv preprint 2403.15362*, 2024.
[[arxiv](https://arxiv.org/abs/2403.15362)]

* <span class='paper-title'>[Reawakening knowledge: Anticipatory recovery from catastrophic interference via structured training](https://arxiv.org/abs/2403.09613).</span>
Yanlai Yang, Matt Jones, Michael C. Mozer, Mengye Ren.
*arXiv preprint 2403.09613*, 2024.
[[arxiv](https://arxiv.org/abs/2403.09613)]

* <span class='paper-title'>[Self-supervised learning of video representations from a child's perspective](https://arxiv.org/abs/2402.00300).</span>
Emin Orhan, Wentao Wang, Alex N. Wang, Mengye Ren, Brenden M. Lake.
*arXiv preprint 2402.00300*, 2024.
[[arxiv](https://arxiv.org/abs/2402.00300)]

* <span class='paper-title'>[Learning and forgetting unsafe examples in large language models](https://arxiv.org/abs/2312.12736).</span>
Jiachen Zhao, Zhun Deng, David Madras, James Zou, Mengye Ren.
*arXiv preprint 2312.12736*, 2023.
[[arxiv](https://arxiv.org/abs/2312.12736)]

* <span class='paper-title'>[LifelongMemory: Leveraging LLMs for answering queries in egocentric videos](https://arxiv.org/abs/2312.05269).</span>
Ying Wang, Yanlai Yang, Mengye Ren.
*arXiv preprint 2312.05269*, 2023.
[[webpage](https://lifelongmemory.github.io/)]
[[arxiv](https://arxiv.org/abs/2312.05269)]

* <span class='paper-title'>[BIM: Block-wise self-supervised learning with masked image modeling](https://arxiv.org/abs/2311.17218).</span>
Yixuan Luo, Mengye Ren, Sai Qian Zhang. 
*arXiv preprint 2311.17218*, 2023.
[[arxiv](https://arxiv.org/abs/2311.17218)]

* <span class='paper-title'>[Learning to reason with relational abstractions](https://arxiv.org/abs/2210.02615).</span>
Andrew J. Nam``*``, Mengye Ren``*``, Chelsea Finn, James L. McClelland.
*arXiv preprint 2210.02615*, 2022.
[[arxiv](https://arxiv.org/abs/2210.02615)]
[[pdf](2022/learning-to-reason-with-relational-abstractions/nam-2022-learning.pdf)]
[[dataset](https://github.com/renmengye/grade-school-math-relational)]

* <span class='paper-title'>[Gaussian-Bernoulli RBMs without tears](https://arxiv.org/abs/2210.10318).</span>
Renjie Liao, Simon Kornblith, Mengye Ren, David J. Fleet, Geoffrey Hinton.
*arXiv preprint 2210.10318*, 2022.
[[arxiv](https://arxiv.org/abs/2210.10318)]

----------------------------------------------------------------------------

## 2023

* <span class='paper-title'>[Scaling forward gradient with local losses](2023/scaling-forward-gradient-with-local-losses).</span>
Mengye Ren, Simon Kornblith, Renjie Liao, Geoffrey Hinton.
*ICLR*, 2023.
[[arxiv](https://arxiv.org/abs/2210.03310)]
[[pdf](2023/scaling-forward-gradient-with-local-losses/ren-2023-scaling.pdf)]
[[code](https://github.com/google-research/google-research/tree/master/local_forward_gradient)]
[[html](2023/scaling-forward-gradient-with-local-losses)]

* <span class='paper-title'>Learning in temporally structured environments.</span>
Matt Jones, Tyler R. Scott, Mengye Ren, Gamaleldin F. Elsayed, Katherine Hermann, David Mayo, Michael C. Mozer.
*ICLR*, 2023.
[[pdf](2023/learning-in-temporally-structured-environments/jones-2023-learning.pdf)]

* <span class='paper-title'>Multitask learning via interleaving: A neural network investigation.</span>
David Mayo, Tyler Scott, Mengye Ren, Gamaleldin Elsayed, Katherine Hermann, Matt Jones, Michael Mozer. *CogSci*, 2023.
[[pdf](2023/multitask-learning-via-interleaving-a-neural-network-investigation/mayo-2023-multitask.pdf)]

* <span class='paper-title'>[Towards unsupervised object detection from LiDAR point clouds](https://arxiv.org/abs/2311.02007).</span>
Lunjun Zhang, Anqi Joyce Yang, Yuwen Xiong, Sergio Casas, Bin Yang, Mengye Ren, Raquel Urtasun.
*CVPR*, 2023.
[[arxiv](https://arxiv.org/abs/2311.02007)]
[[pdf](2023/towards-unsupervised-object-detection-from-lidar-point-clouds/zhang-2023-towards.pdf)]
[[video](https://research-assets.waabi.ai/wp-content/uploads/2023/05/oyster_video-2.mp4)]
[[website](https://waabi.ai/oyster)]

* <span class='paper-title'>Egocentric video comprehension via large language model inner speech.</span>
Ying Wang, Dongdong Sun, Rui Chen, Yanlai Yang, Mengye Ren.
*3rd International Ego4D Workshop at CVPR*, 2023.
[[pdf](2023/egocentric-video-comprehension-via-large-language-model-inner-speech/wang-2023-egocentric.pdf)]

----------------------------------------------------------------------------

## 2022

* <span class='paper-title'>[Learning to reason with relational abstractions](https://arxiv.org/abs/2210.02615).</span>
Andrew J. Nam``*``, Mengye Ren``*``, Chelsea Finn, James L. McClelland.
*NeurIPS MATH-AI Worshop*, 2022.
[[arxiv](https://arxiv.org/abs/2210.02615)]
[[pdf](2022/learning-to-reason-with-relational-abstractions/nam-2022-learning.pdf)]
[[dataset](https://github.com/renmengye/grade-school-math-relational)]

* <span class='paper-title'>Neural network online training with sensitivity to multiscale temporal structure.</span>
Matt Jones, Tyler R. Scott, Gamaleldin F. Elsayed, Mengye Ren, Katherine Hermann, David Mayo, Michael C. Mozer.
*NeurIPS MemARI Workshop*, 2022.
[[pdf](2022/neural-network-online-training-with-sensitivity-to-multiscale-temporal-structure/jones-2022-neural.pdf)]

* <span class='paper-title'>[Rethinking closed-loop training for autonomous driving](https://arxiv.org/abs/2306.15713).</span>
Chris Zhang``*``, Runsheng Guo``*``, Wenyuan Zeng``*``, Yuwen Xiong, Binbin Dai, Rui Hu, Mengye Ren, Raquel Urtasun.
*ECCV*, 2022.
<!-- [[pdf](https://www.ecva.net/papers/eccv_2022/papers_ECCV/papers/136990259.pdf)] -->
[[arxiv](https://arxiv.org/abs/2306.15713)]
[[pdf](2022/rethinking-closed-loop-training-for-autonomous-driving/zhang-2022-rethinking.pdf)]

* <span class='paper-title'>Open-world machine learning with limited labeled data.</span>
Mengye Ren. *Ph.D. Thesis, University of Toronto*, 2022.
<!-- [[pdf](https://tspace.library.utoronto.ca/bitstream/1807/123215/2/Ren_Mengye_202206_PhD_thesis.pdf)] -->
[[pdf](2022/phd-thesis/Ren_Mengye_202206_PhD_thesis.pdf)]

* <span class='paper-title'>[Probing few-shot generalization with attributes](2022/probing-few-shot-generalization-with-attributes).</span>
Mengye Ren``*``, Eleni Triantafillou``*``, Kuan-Chieh Wang``*``, James Lucas``*``, Jake Snell, Xaq Pitkow, Andreas S. Tolias, Richard Zemel.
*arXiv preprint 2012.05895*, 2020.
[[arxiv](https://arxiv.org/abs/2012.05895)]
[[pdf](2022/probing-few-shot-generalization-with-attributes/ren-2022-probing.pdf)]
[[video](https://slideslive.at/38941548/flexible-fewshot-learning-of-contextual-similarities)]
[[html](2022/probing-few-shot-generalization-with-attributes)]

* <span class='paper-title'>[Online unsupervised learning of visual representations and categories](2022/online-unsupervised-learning-of-visual-representations-and-categories).</span>
Mengye Ren, Tyler R. Scott, Michael L. Iuzzolino, Michael C. Mozer, Richard Zemel.
*arXiv preprint 2109.05675*, 2021.
[[arxiv](https://arxiv.org/abs/2109.05675)]
[[pdf](2022/online-unsupervised-learning-of-visual-representations-and-categories/ren-2022-online.pdf)]
[[code](https://github.com/renmengye/online-unsup-proto-net)]
[[html](2022/online-unsupervised-learning-of-visual-representations-and-categories)]

----------------------------------------------------------------------------

## 2021

* <span class='paper-title'>[Self-supervised representation learning from flow equivariance](2021/self-supervised-representation-learning-from-flow-equivariance).</span>
Yuwen Xiong, Mengye Ren, Wenyuan Zeng, Raquel Urtasun.
*ICCV*, 2021.
[[arxiv](https://arxiv.org/abs/2101.06553)]
[[pdf](2021/self-supervised-representation-learning-from-flow-equivariance/xiong-2021-self.pdf)]
[[html](2021/self-supervised-representation-learning-from-flow-equivariance)]

* <span class='paper-title'>Adversarial attacks on multi-agent communication.</span>
James Tu``*``, Tsunhsuan Wang``*``, Jingkang Wang, Sivabalan Manivasagam, Mengye Ren, Raquel Urtasun.
*ICCV*, 2021.
[[arxiv](https://arxiv.org/abs/2101.06560)]

* <span class='paper-title'>Just label what you need: Fine-grained active selection for perception and prediction through partially labeled scenes.</span>
Sean Segal, Nishanth Kumar, Sergio Casas, Wenyuan Zeng, Mengye Ren, Jingkang Wang, Raquel Urtasun.
*CoRL*, 2021.
[[arxiv](https://arxiv.org/abs/2104.03956)]

* <span class='paper-title'>Exploring adversarial robustness of multi-sensor perception systems in self driving.</span>
James Tu, Huichen Li, Xinchen Yan, Mengye Ren, Yun Chen, Ming Liang, Eilyan Bitar, Ersin Yumer, Raquel Urtasun.
*CoRL*, 2021.
[[arxiv](https://arxiv.org/abs/2101.06784)]

* <span class='paper-title'>[SketchEmbedNet: Learning novel concepts by imitating drawings](2021/sketch-embed-net-learning-novel-concepts-by-imitating-drawings).</span>
Alexander Wang``*``, Mengye Ren``*``, Richard Zemel.
*ICML*, 2021.
[[arxiv](https://arxiv.org/abs/2009.04806)]
[[pdf](2021/sketch-embed-net-learning-novel-concepts-by-imitating-drawings/wang-2021-sketch.pdf)]
[[html](2021/sketch-embed-net-learning-novel-concepts-by-imitating-drawings)]

* <span class='paper-title'>[Wandering within a world: Online contextualized few-shot learning](2021/wandering-within-a-world-online-contextualized-few-shot-learning).</span>
Mengye Ren, Michael L. Iuzzolino, Michael C. Mozer, Richard Zemel.
*ICLR*, 2021.
[[arxiv](https://arxiv.org/abs/2007.04546)]
[[pdf](2021/wandering-within-a-world-online-contextualized-few-shot-learning/ren-2021-wandering.pdf)]
[[code](https://github.com/renmengye/oc-fewshot-public)]
[[video](https://slideslive.com/38931573/wandering-within-a-world-online-contextualized-fewshot-learning)]
[[html](2021/wandering-within-a-world-online-contextualized-few-shot-learning)]

* <span class='paper-title'>[Theoretical bounds on estimation error for meta-learning](2021/theoretical-bounds-on-estimation-error-for-meta-learning).</span>
James Lucas, Mengye Ren, Irene Kameni, Toniann Pitassi, Richard Zemel.
*ICLR*, 2021.
[[arxiv](https://arxiv.org/abs/2010.07140)]
[[pdf](2021/theoretical-bounds-on-estimation-error-for-meta-learning/lucas-2021-theoretical.pdf)]
[[video](https://slideslive.com/38954221/theoretical-bounds-on-estimation-error-for-metalearning)]
[[html](2021/theoretical-bounds-on-estimation-error-for-meta-learning)]

* <span class='paper-title'>[Perceive, attend, and drive: Learning spatial attention for safe self-driving](2021/perceive-attend-and-drive-learning-spatial-attention-for-safe-self-driving).</span>
Bob Wei``*``, Mengye Ren``*``, Wenyuan Zeng, Ming Liang, Bin Yang, Raquel Urtasun.
*ICRA*, 2021.
[[arxiv](https://arxiv.org/abs/2011.01153)]
[[pdf](2021/perceive-attend-and-drive-learning-spatial-attention-for-safe-self-driving/wei-2021-perceive.pdf)]
[[video](https://youtu.be/3ffaQ2PIQCM)]
[[html](2021/perceive-attend-and-drive-learning-spatial-attention-for-safe-self-driving)]

* <span class='paper-title'>AdvSim: Generating safety-critical scenarios for self-driving vehicles.</span>
Jingkang Wang, Ava Pun, James Tu, Sivabalan Manivasagam, Abbas Sadat, Sergio Casas, Mengye Ren, Raquel Urtasun.
*CVPR*, 2021.
[[arxiv](https://arxiv.org/abs/2101.06549)]
[[pdf](2021/advsim-generating-safety-critical-scenarios-for-self-driving-vehicles/wang-2021-advsim.pdf)]

* <span class='paper-title'>SceneGen: Learning to generate realistic traffic scenes.</span>
Shuhan Tan``*``, Kelvin Wong``*``, Shenlong Wang, Sivabalan Manivasagam, Mengye Ren, Raquel Urtasun.
*CVPR*, 2021.
[[arxiv](https://arxiv.org/abs/2101.06541)]
[[pdf](2021/scenegen-learning-to-generate-realistic-traffic-scenes/tan-2021-scenegen.pdf)]

----------------------------------------------------------------------------

## 2020

* <span class='paper-title'>[LoCo: Local contrastive representation learning](2020/loco-local-contrastive-representation-learning).</span>
Yuwen Xiong, Mengye Ren, Raquel Urtasun.
*NeurIPS*, 2020.
[[arxiv](https://arxiv.org/abs/2008.01342)]
[[pdf](2020/loco-local-contrastive-representation-learning/xiong-2020-loco.pdf)]
[[video](https://slideslive.com/38936405/loco-local-contrastive-representation-learning)]
[[html](2020/loco-local-contrastive-representation-learning)]

* <span class='paper-title'>Multi-label incremental few-shot learning for medical image pathology classifiers.</span>
Laleh Seyyed-Kalantari, Karsten Roth, Mengye Ren, Parsa Torabian, Joseph P. Cohen, Marzyeh Ghassemi.
*Medical Imaging Meets NeurIPS Workshop*, 2020.
[[video](https://slideslive.com/38942997/multilabel-incremental-fewshot-learning-for-medical-image-pathology-classifiers)]

* <span class='paper-title'>Flexible Few-Shot Learning of Contextual Similarities.</span>
Mengye Ren``*``, Eleni Triantafillou``*``, Kuan-Chieh Wang``*``, James Lucas``*``, Jake Snell, Xaq Pitkow, Andreas S. Tolias, Richard Zemel.
*NeurIPS Meta-Learning Workshop*, 2020.
[[pdf](https://meta-learn.github.io/2020/papers/49_paper.pdf)]
[[video](https://slideslive.at/38941548/flexible-fewshot-learning-of-contextual-similarities)]

* <span class='paper-title'>Learning to communicate and correct pose errors.</span>
Nicholas Vadivelu, Mengye Ren, James Tu, Jingkang Wang, Raquel Urtasun.
*CoRL*, 2020.
[[arxiv](https://arxiv.org/abs/2011.05289)]
[[video](https://www.youtube.com/watch?v=Qu5KJofLRvs)]

* <span class='paper-title'>[Multi-agent routing value iteration network](2020/multi-agent-routing-value-iteration-network).</span>
Quinlan Sykora``*``, Mengye Ren``*``, Raquel Urtasun.
*ICML*, 2020.
[[arxiv](https://arxiv.org/abs/2007.05096)]
[[pdf](2020/multi-agent-routing-value-iteration-network/sykora-2020-multi.pdf)]
[[code](https://github.com/uber-research/MARVIN)]
[[video](https://slideslive.com/38927801/multiagent-routing-value-iteration-network-marvin)]
[[html](2020/multi-agent-routing-value-iteration-network)]

* <span class='paper-title'>Cost-efficient online hyperparameter optimization.</span>
Jingkang Wang``*``, Mengye Ren``*``, Ilija Bogunovic, Yuwen Xiong, Raquel Urtasun.
*ICML RealML Workshop*, 2020.
[[arxiv](https://arxiv.org/abs/2101.06590)]
[[pdf](2020/cost-efficient-online-hyperparameter-optimization/wang-2020-cost.pdf)]
[[slide](https://realworldml.github.io/files/slides/28_slide.pdf)]

* <span class='paper-title'>Perceive, predict, and plan: Safe motion planning through interpretable semantic representations.</span>
Abbas Sadat``*``, Sergio Casas Romero``*``, Mengye Ren, Xinyu Wu, Pranaab Dhawan, Raquel Urtasun.
*ECCV*, 2020.
[[arxiv](https://arxiv.org/abs/2008.05930)]

* <span class='paper-title'>End-to-end contextual perception and prediction with interaction transformer.</span>
Lingyun (Luke) Li, Bin Yang, Ming Liang, Wenyuan Zeng, Mengye Ren, Sean Segal, Raquel Urtasun.
*IROS*, 2020.
[[arxiv](https://arxiv.org/abs/2008.05927)]

* <span class='paper-title'>Physically realizable adversarial examples for LiDAR object detection.</span>
James Tu, Mengye Ren, Sivabalan Manivasagam, Ming Liang, Bin Yang, Richard Du, Frank Cheng, Raquel Urtasun.
*CVPR*, 2020.
[[arxiv](https://arxiv.org/abs/2004.00543)]
[[video](https://www.youtube.com/watch?v=yP47irVRGZI)]

----------------------------------------------------------------------------

## 2019

* <span class='paper-title'>Learning to remember from a multi-task teacher.</span>
Yuwen Xiong``*``, Mengye Ren``*``, Raquel Urtasun.
*arXiv preprint 1910.04650*, 2019.
[[arxiv](https://arxiv.org/abs/1910.04650)]

* <span class='paper-title'>[Incremental few-shot learning with attention attractor networks](2019/incremental-few-shot-learning-with-attention-attractor-networks).</span>
Mengye Ren, Renjie Liao, Ethan Fetaya, Richard S. Zemel.
*NeurIPS*, 2019.
[[arxiv](https://arxiv.org/abs/1810.07218)]
[[code](https://github.com/renmengye/inc-few-shot-attractor-public)]
[[html](2019/incremental-few-shot-learning-with-attention-attractor-networks)]

* <span class='paper-title'>Information-theoretic limitations on novel task generalization.</span>
James Lucas, Mengye Ren, Richard S. Zemel.
*NeurIPS Workshop on Machine Learning with Guarantees*, 2019.
[[pdf](https://drive.google.com/file/d/10pNGWyVYruL-yjjF3NVoKp6GjLZDWj8U/view)]

* <span class='paper-title'>Deformable filter convolution for point cloud reasoning.</span>
Yuwen Xiong``*``, Mengye Ren``*``, Renjie Liao, Kelvin Wong, Raquel Urtasun.
*NeurIPS Workshop on Sets & Partitions*, 2019.
[[arxiv](https://arxiv.org/abs/1907.13079)]

* <span class='paper-title'>Identifying unknown instances for autonomous driving.</span>
Kelvin Wong, Shenlong Wang, Mengye Ren, Ming Liang, Raquel Urtasun.
*CoRL*, 2019.
[[arxiv](https://arxiv.org/abs/1910.11296)]

* <span class='paper-title'>Jointly learnable behavior and trajectory planning for self-driving vehicles.</span>
Abbas Sadat``*``, Mengye Ren``*``, Andrei Pokrovsky, Yen-Chen Lin, Ersin Yumer, Raquel Urtasun.
*IROS*, 2019.
[[arxiv](https://arxiv.org/abs/1910.04586)]

* <span class='paper-title'>[Graph hypernetworks for neural architecture search](2019/graph-hypernetworks-for-neural-architecture-search).</span>
Chris Zhang, Mengye Ren, Raquel Urtasun.
*ICLR*, 2019.
[[arxiv](https://arxiv.org/abs/1810.05749)]
[[html](2019/graph-hypernetworks-for-neural-architecture-search)]

----------------------------------------------------------------------------

## 2018

* <span class='paper-title'>[Learning to reweight examples for robust deep learning](2018/learning-to-reweight-examples-for-robust-deep-learning).</span>
Mengye Ren, Wenyuan Zeng, Bin Yang, Raquel Urtasun.
*ICML*, 2018.
[[arxiv](https://arxiv.org/abs/1803.09050)]
[[code](https://github.com/uber-research/learning-to-reweight-examples)]
[[video](https://vimeo.com/287808016)]
[[html](2018/learning-to-reweight-examples-for-robust-deep-learning)]

* <span class='paper-title'>[SBNet: Sparse blocks network for fast inference](2018/sbnet-sparse-blocks-network-for-fast-inference).</span>
Mengye Ren``*``, Andrei Pokrovsky``*``, Bin Yang``*``, Raquel Urtasun.
*CVPR*, 2018.
[[link](sbnet/index.html)]
[[arxiv](https://arxiv.org/abs/1801.02108)]
[[blog](https://eng.uber.com/sbnet)]
[[code](https://github.com/uber/sbnet)]
[[html](2018/sbnet-sparse-blocks-network-for-fast-inference)]

* <span class='paper-title'>[Meta-learning for semi-supervised few-shot classification](2018/meta-learning-for-semi-supervised-few-shot-classification).</span>
Mengye Ren, Eleni Triantafillou``*``, Sachin Ravi``*``, Jake Snell, Kevin
Swersky, Joshua B. Tenenbaum, Hugo Larochelle, Richard S. Zemel.
*ICLR*, 2018.
[[link](fewshotssl/index.html)]
[[arxiv](https://arxiv.org/abs/1803.00676)]
[[code](https://github.com/renmengye/few-shot-ssl-public)]
[[html](2018/meta-learning-for-semi-supervised-few-shot-classification)]

* <span class='paper-title'>[Understanding short-horizon bias in stochastic meta-optimization](2018/understanding-short-horizon-bias-in-stochastic-meta-optimization).</span>
Yuhuai Wu``*``, Mengye Ren``*``, Renjie Liao, Roger B. Grosse.
*ICLR*, 2018.
[[link](metaoptim/index.html)]
[[arxiv](https://arxiv.org/abs/1803.02021)]
[[code](https://github.com/renmengye/meta-optim-public)]
[[html](2018/understanding-short-horizon-bias-in-stochastic-meta-optimization)]

----------------------------------------------------------------------------

## 2017

* <span class='paper-title'>The reversible residual network: Backpropagation without storing actications.</span>
Aidan N. Gomez``*``, Mengye Ren``*``, Raquel Urtasun, Roger B. Grosse.
*NIPS*, 2017.
[[link](revnet/index.html)]
[[arxiv](https://arxiv.org/abs/1707.04585)]
[[code](https://github.com/renmengye/revnet-public)]

* <span class='paper-title'>Normalizing the normalizers: Comparing and extending network normalization schemes.</span>
Mengye Ren``*``, Renjie Liao``*``, Raquel Urtasun, Fabian H. Sinz, Richard S. Zemel.
*ICLR*, 2017.
[[link](divnorm/index.html)]
[[arxiv](https://arxiv.org/abs/1611.04520)]
[[code](https://github.com/renmengye/div-norm)]

* <span class='paper-title'>End-to-end instance segmentation with recurrent attention.</span>
Mengye Ren, Richard S. Zemel.
*CVPR*, 2017.
[[link](recattend/index.html)]
[[arxiv](https://arxiv.org/abs/1605.09410)]
[[code](https://github.com/renmengye/rec-attend-public)]
[[video](https://www.youtube.com/watch?v=oHgUowLph7E)]

----------------------------------------------------------------------------

## 2015

* <span class='paper-title'>Exploring models and data for image question answering.</span>
Mengye Ren, Ryan Kiros, Richard S. Zemel.
*NIPS*, 2015.
[[link](imageqa/index.html)]
[[arxiv](https://arxiv.org/abs/1505.02074)]
[[results](imageqa/results)]
[[dataset](imageqa/data/cocoqa)]
[[code](https://github.com/renmengye/imageqa-public)]
[[question generation](https://github.com/renmengye/imageqa-qgen)]

<div class="ribbon"></div>

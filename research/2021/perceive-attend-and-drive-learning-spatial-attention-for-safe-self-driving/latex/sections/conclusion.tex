% !TEX root = ../main.tex
\vspace{-0.1in}
\section{Conclusion}
In this work, we propose an end-to-end learned, sparse visual attention
mechanism for self-driving, where the sparse attention mask gates the feature backbone
computation. As opposed to existing methods that focus on using attention for perception only,
our attention masks are directly optimized for motion planning, which enables our network to output
better planned trajectories while achieving more efficiency with higher sparsity. In future work,
the attention module can be extended to have recurrent feedbacks from the output layers
to better leverage temporal information.

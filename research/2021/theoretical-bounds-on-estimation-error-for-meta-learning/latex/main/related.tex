\section{Related work}

An early version of this work \citep{lucas2019information} presented a restricted version of Theorem~\ref{thm:env_lower_bound}. The current version includes significantly more content, including more general lower bounds and corresponding upper bounds in a hierarchical Bayesian model of meta-learning (Section~\ref{sec:hierarchical_bayes}).

\citet{baxter2000model} introduced a formulation for inductive bias learning where the learner is embedded in an environment of multiple tasks. The learner must find a hypothesis space which enables good generalization on average tasks within the environment, using finite samples. In our setting, the learner is not explicitly tasked with finding a reduced hypothesis space but instead learns
using a general two-stage approach, which matches the standard meta-learning paradigm \citep{vilalta2002perspective}. In the first stage an inductive bias is extracted from the data, and in the second stage the learner estimates using data from a novel task distribution. Further, we focus on bounding minimax risk of meta learners. Under minimax risk, an optimal learner achieves minimum error on the hardest learning problem in the environment. While average case risk of meta learners is more commonly studied, recent work has turned attention towards the minimax setting \citep{pmlr-v75-kpotufe18a, NIPS2019_9179, hanneke2020no, kalan2020minimax, mehta2012minimax}. The worst-case error 
in meta-learning is particularly important in safety-critical systems, for example in medical diagnosis.

\citet{kalan2020minimax} study the minimax risk of transfer learning. In their setting, the learner is provided with a large amount of data from a single source task and is tasked with generalizing to a target task with a limited amount of data. They assume relatedness between tasks by imposing closeness in parameter-space (whereas in our setting, we assume closeness in distribution via KL divergence). They prove only lower bounds, but notably generalize beyond the linear setting towards single layer neural networks.

There is a large volume of prior work studying upper-bounds on generalization error in multi-task environments \citep{ben2008notion, ben2010theory, pentina2014pac, amit2017meta, mehta2012minimax}. While the approaches in these works vary, one common factor is the need to characterize task-relatedness. Broadly, these approaches either assume a shared distribution for sampling tasks \citep{baxter2000model, pentina2014pac, amit2017meta}, or a measure of distance between distributions \citep{ben2008notion, ben2010theory, mohri2012new}. Our lower-bounds utilize a weak form of task relatedness, assuming that the environment contains a finite set that is suitably separated in parameter space but close in KL divergence---this set of assumptions also arises often when computing \iid minimax lower bounds \citep{loh2017lower}.

One practical approach to meta-learning
is learning a linear mapping on top of a learned feature space. 
Prototypical Networks~\citep{snell2017prototypical} effectively learn a  discriminative embedding function and performs linear classification on top using the novel task data.
Analyzing these approaches is challenging due to metric-learning inspired objectives (that require non-\iid sampling) and the simultaneous learning of feature mappings and top-level linear functions. Though some progress has been made \citep{jin2009regularized, saunshi2019theoretical, wang2019multitask, du2020few}. \citet{maurer2009transfer}, for example, explores linear models fitted over a shared linear feature map in a Hilbert space. Our results can be applied in these settings if a suitable packing of the representation space is defined.

Other approaches to meta-learning aim to parameterize learning algorithms themselves. Traditionally, this has been achieved by hyper-parameter tuning~\citep{gpml,stn} but
recent fully parameterized optimizers also show promising performance in deep neural network optimization~\citep{l2l}, few-shot learning~\citep{ravi2016optimization}, unsupervised learning~\citep{metaunsup}, and reinforcement learning~\citep{duan2016rl2}. Yet another approach learns the initialization of task-specific parameters, that are further adapted through regular gradient descent. Model-Agnostic Meta-Learning \citep{finn2017model}, or MAML, augments the global parameters with a meta-initialization of the weight parameters. \citet{grant2018recasting} recast MAML in terms of inference in a Bayesian hierarchical model.
In Section~\ref{sec:hierarchical_bayes}, we consider learning in a hierarchical environment of linear models and provide both lower and upper bounds on the error of estimating the parameters of a novel linear regression problem.

Lower bounding estimation error is a critical component of understanding learning problems (and algorithms). Accordingly, there is a large body of literature producing such lower bounds \citep{khas1979lower, yang1999information, loh2017lower}. We focus on producing lower-bounds for parameter estimation using local packing sets, but expect that extending these results to density estimation or non-parametric estimation is feasible.
%In this work, we analyze simple parameter spaces for linear regression (ignoring sparsity, and over-parameterization), and explore a hierarchical model of linear regression in which data from multiple linear models is observed and generalization to a new model is desired.

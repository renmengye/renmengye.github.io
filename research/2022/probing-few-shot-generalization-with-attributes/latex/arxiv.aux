\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{plainnat}
\citation{lake2011oneshot,matchingnet}
\citation{fewshotssl}
\citation{closerlook,broadstudy,triantafillou2019meta}
\providecommand \oddpage@label [2]{}
\jmlr@workshop{}
\jmlr@title{}{Probing Few-Shot Generalization with Attributes}
\jmlr@author{\Name {Mengye Ren${}^*$}\thanks {*Equal contribution} \Email {mengye@nyu.edu}\\ \addr New York University; Google\\ \Name {Eleni Triantafillou${}^*$} \Email {etriantafillou@google.com}\\ \addr Google\\ \Name {Kuan-Chieh Wang${}^*$} \Email {wangkua1@stanford.edu}\\ \addr Stanford University\\\^^M\Name {James Lucas${}^*$} \Email {jlucas@cs.toronto.edu}\\ \addr NVIDIA\\ \Name {Jake Snell} \Email {jsnell@cs.toronto.edu}\\ \addr University of Toronto; Vector Institute\\ \Name {Xaq Pitkow} \Email {xaq@rice.edu}\\ \addr Rice University; Baylor College of Medicine\\ \Name {Andreas S. Tolias} \Email {astolias@bcm.edu}\\ \addr Baylor College of Medicine; Rice University\\ \Name {Richard Zemel} \Email {zemel@cs.columbia.edu}\\ \addr Columbia University; University of Toronto; Vector Institute; Canadian Institute for Advanced Research\\ }{\Name {Mengye Ren${}^*$}\thanks {*Equal contribution} \Email {mengye@nyu.edu}\\ \addr New York University; Google\\ \Name {Eleni Triantafillou${}^*$} \Email {etriantafillou@google.com}\\ \addr Google\\ \Name {Kuan-Chieh Wang${}^*$} \Email {wangkua1@stanford.edu}\\ \addr Stanford University\\\^^M\Name {James Lucas${}^*$} \Email {jlucas@cs.toronto.edu}\\ \addr NVIDIA\\ \Name {Jake Snell} \Email {jsnell@cs.toronto.edu}\\ \addr University of Toronto; Vector Institute\\ \Name {Xaq Pitkow} \Email {xaq@rice.edu}\\ \addr Rice University; Baylor College of Medicine\\ \Name {Andreas S. Tolias} \Email {astolias@bcm.edu}\\ \addr Baylor College of Medicine; Rice University\\ \Name {Richard Zemel} \Email {zemel@cs.columbia.edu}\\ \addr Columbia University; University of Toronto; Vector Institute; Canadian Institute for Advanced Research\\ }
\newlabel{jmlrstart}{{}{1}{}{Doc-Start}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.0.1}\protected@file@percent }
\citation{roschmervis1975family}
\citation{sariyildiz2021}
\citation{arnold2021embedding}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces \textbf  {Sample FSAL{} episodes using Celeb-A (left) and Zappos-50K (right).} Positive and negative examples are sampled according to attributes.\relax }}{2}{figure.caption.1}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{fig:sample}{{1}{2}{\textbf {Sample \taskname {} episodes using Celeb-A (left) and Zappos-50K (right).} Positive and negative examples are sampled according to attributes.\relax }{figure.caption.1}{}}
\citation{attributezsl}
\@writefile{toc}{\contentsline {section}{\numberline {2}Few-Shot Attribute Learning}{3}{section.0.2}\protected@file@percent }
\citation{simclr}
\citation{simclr}
\@writefile{toc}{\contentsline {section}{\numberline {3}Experiment Methodology}{4}{section.0.3}\protected@file@percent }
\newlabel{sec:method}{{3}{4}{Experiment Methodology}{section.0.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Stage I: Representation Learning}{4}{subsection.0.3.1}\protected@file@percent }
\newlabel{sec:ft}{{3.1}{4}{Stage I: Representation Learning}{subsection.0.3.1}{}}
\@writefile{toc}{\contentsline {paragraph}{Supervised:}{4}{section*.2}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Unsupervised:}{4}{section*.3}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Unsupervised-then-Finetuning:}{4}{section*.4}\protected@file@percent }
\citation{protonet}
\citation{matchingnet}
\citation{protonet}
\citation{closerlook}
\citation{attributezsl}
\citation{czsl}
\citation{lake2011oneshot}
\citation{fei2006one,lake2011oneshot,matchingnet}
\citation{Thrun1998}
\citation{closerlook,anil}
\citation{fewshotssl}
\citation{triantafillou2019meta}
\citation{alfassy2019laso,li2021compositional}
\citation{tokmakov2019learning}
\citation{xiang2019incremental}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Stage II: Few-Shot Learning}{5}{subsection.0.3.2}\protected@file@percent }
\newlabel{sec:fsl}{{3.2}{5}{Stage II: Few-Shot Learning}{subsection.0.3.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Related Work}{5}{section.0.4}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Few-shot learning:}{5}{section*.6}\protected@file@percent }
\citation{ferrari2007attribute,farhadi2009describe,farhadi2010attribute,wang2010discriminative}
\citation{koh2020concept}
\citation{cub,zappos,celeba,patterson2016coco,pham2021attribute}
\citation{farhadi2009describe,labelembed,goodbadugly,attributezsl,ezzsl,evaluateoutput}
\citation{descriptionzsl}
\citation{farhadi2009describe}
\citation{wang2019survey}
\citation{attributezsl}
\citation{czsl,taskdriven,taskaware,unseencomposition}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces \textbf  {Differences between zero-shot learning (ZSL), compositional ZSL (CZSL), few-shot learning (FSL), and our newly proposed few-shot attribute learning{} (FSAL{}).} Our task requires the model to generalize to new attributes.\relax }}{6}{table.caption.5}\protected@file@percent }
\newlabel{tab:benchmarkdiff}{{1}{6}{\textbf {Differences between zero-shot learning (ZSL), compositional ZSL (CZSL), few-shot learning (FSL), and our newly proposed \titlelower {} (\taskname {}).} Our task requires the model to generalize to new attributes.\relax }{table.caption.5}{}}
\@writefile{toc}{\contentsline {paragraph}{Attribute learning:}{6}{section*.7}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Zero-shot learning:}{6}{section*.8}\protected@file@percent }
\citation{baxter2000model,ben2008notion,ben2010theory,pentina2014,amit2018meta,lucas2020lb}
\citation{arnold2021embedding}
\citation{sariyildiz2021}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces \textbf  {5- and 20-shot attribute learning results on Celeb-A and Zappos-50K.} Methods can be supervised by 1) \textit  {``E''}=episode binary labels, 2) \textit  {``A''}=attributes, and 3) \textit  {``C''}=face identity. The best is \textbf  {bolded} and the second best is \underline  {underlined}. \relax }}{7}{table.caption.10}\protected@file@percent }
\newlabel{tab:main}{{2}{7}{\textbf {5- and 20-shot attribute learning results on Celeb-A and Zappos-50K.} Methods can be supervised by 1) \textit {``E''}=episode binary labels, 2) \textit {``A''}=attributes, and 3) \textit {``C''}=face identity. The best is \textbf {bolded} and the second best is \ul {underlined}. \relax }{table.caption.10}{}}
\@writefile{toc}{\contentsline {paragraph}{Generalization to novel tasks:}{7}{section*.9}\protected@file@percent }
\citation{celeba}
\citation{zappos}
\citation{deng2009imagenet}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces \textbf  {Combination of different representation \& few-shot learners on 20-shot attribute learning.} Note: Meta-NN = MatchingNet, Meta-NC = ProtoNet, Meta-LR = MAML/ANIL.\relax }}{8}{table.caption.12}\protected@file@percent }
\newlabel{tab:combo}{{3}{8}{\textbf {Combination of different representation \& few-shot learners on 20-shot attribute learning.} Note: Meta-NN = MatchingNet, Meta-NC = ProtoNet, Meta-LR = MAML/ANIL.\relax }{table.caption.12}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Experiments}{8}{section.0.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Datasets}{8}{subsection.0.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Episode construction:}{8}{section*.11}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Methods for Comparison}{8}{subsection.0.5.2}\protected@file@percent }
\newlabel{sec:baselines}{{5.2}{8}{Methods for Comparison}{subsection.0.5.2}{}}
\citation{closerlook}
\citation{matchingnet}
\citation{maml}
\citation{anil}
\citation{protonet}
\citation{tafenet}
\citation{tadam}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces  \textbf  { Comparison of representation learning methods with respect to their ability to predict training and testing attributes.} Standard methods such as ProtoNet and SA perform well on training attributes but do not transfer well to novel ones (large training vs. test gaps in \textcolor {red}{red}). \relax }}{9}{table.caption.13}\protected@file@percent }
\newlabel{tab:gap}{{4}{9}{\textbf { Comparison of representation learning methods with respect to their ability to predict training and testing attributes.} Standard methods such as ProtoNet and SA perform well on training attributes but do not transfer well to novel ones (large training vs. test gaps in \textcolor {red}{red}). \relax }{table.caption.13}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces \textbf  {Number of projection layers (L) during finetuning, and whether they are discarded (D) during testing.} Numbers are from Celeb-A 20-shot. $\Delta $ denotes changes compared to no finetuning.\relax }}{9}{table.caption.13}\protected@file@percent }
\newlabel{tab:projection}{{5}{9}{\textbf {Number of projection layers (L) during finetuning, and whether they are discarded (D) during testing.} Numbers are from Celeb-A 20-shot. $\Delta $ denotes changes compared to no finetuning.\relax }{table.caption.13}{}}
\citation{resnet,tadam}
\citation{cam}
\citation{cam}
\@writefile{lot}{\contentsline {table}{\numberline {6}{\ignorespaces \textbf  {5- and 20-shot results on ImageNet.} Learners uses logistic regression (LR) at test time.\relax }}{10}{table.caption.15}\protected@file@percent }
\newlabel{tab:imagenet-main}{{6}{10}{\textbf {5- and 20-shot results on ImageNet.} Learners uses logistic regression (LR) at test time.\relax }{table.caption.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {7}{\ignorespaces \textbf  {20-shot FSAL{} on ImageNet} with different few-shot learners.\relax }}{10}{table.caption.15}\protected@file@percent }
\newlabel{subtab:imagenet-fsl}{{7}{10}{\textbf {20-shot \taskname {} on ImageNet} with different few-shot learners.\relax }{table.caption.15}{}}
\@writefile{lot}{\contentsline {table}{\numberline {8}{\ignorespaces \textbf  {Training vs. test attributes} of 20-shot FSAL{} on ImageNet.\relax }}{10}{table.caption.15}\protected@file@percent }
\newlabel{subtab:imagenet-traintest-gap}{{8}{10}{\textbf {Training vs. test attributes} of 20-shot \taskname {} on ImageNet.\relax }{table.caption.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces  \textbf  {Visualization of few-shot classifiers using CAM\nobreakspace  {}\citep  {cam}, on top of different representations.} Left: Celeb-A; Right: Zappos-50K. Target attributes that define the episode are shown above and images are from the query set of the positive class at test time.\relax }}{10}{figure.caption.16}\protected@file@percent }
\newlabel{fig:viz}{{2}{10}{\textbf {Visualization of few-shot classifiers using CAM~\citep {cam}, on top of different representations.} Left: Celeb-A; Right: Zappos-50K. Target attributes that define the episode are shown above and images are from the query set of the positive class at test time.\relax }{figure.caption.16}{}}
\@writefile{toc}{\contentsline {paragraph}{Implementation details:}{10}{section*.14}\protected@file@percent }
\citation{cam}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces \textbf  {How many examples are needed for FSAL{}?} Performance increases with number of shots, even when given the binary ground-truth attribute vector (\textbf  {GT}), suggesting that there is greater ambiguity in FSAL{} than in standard FSL.\relax }}{11}{figure.caption.17}\protected@file@percent }
\newlabel{fig:nshot}{{3}{11}{\textbf {How many examples are needed for \taskname {}?} Performance increases with number of shots, even when given the binary ground-truth attribute vector (\textbf {GT}), suggesting that there is greater ambiguity in \taskname {} than in standard FSL.\relax }{figure.caption.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces \textbf  {Correlation between readout AUC and few-shot acc. using UFTA}. Variance can be explained by the challenge of predicting attributes and the ambiguity of FSAL{}. More shots reduce variance and improve correlation.\relax }}{11}{figure.caption.17}\protected@file@percent }
\newlabel{fig:corr}{{4}{11}{\textbf {Correlation between readout AUC and few-shot acc. using \uftsa }. Variance can be explained by the challenge of predicting attributes and the ambiguity of \taskname {}. More shots reduce variance and improve correlation.\relax }{figure.caption.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Comparing Various Methods for FSAL{}}{11}{subsection.0.5.3}\protected@file@percent }
\newlabel{sec:experiments:results}{{5.3}{11}{Comparing Various Methods for \taskname {}}{subsection.0.5.3}{}}
\@writefile{toc}{\contentsline {paragraph}{Visualizing few-shot classifiers:}{11}{section*.18}\protected@file@percent }
\citation{simclr}
\@writefile{toc}{\contentsline {paragraph}{Number of shots and task ambiguity:}{12}{section*.19}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Ablation studies:}{12}{section*.20}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Analysis of Few-Shot Generalization}{12}{subsection.0.5.4}\protected@file@percent }
\newlabel{sec:analysis}{{5.4}{12}{Analysis of Few-Shot Generalization}{subsection.0.5.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Investigating the cause of generalization issues:}{12}{section*.21}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Transferability score:}{12}{section*.23}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces  \looseness =-10000 \textbf  {Few-shot performance vs. transferability across training and test attributes.} \textbf  {A:} Transferability score (T-score) is computed based on the AUC of a test attribute predicted by a logistic regression model on a set of training attributes. 100 different random splits across train/test attributes per split are used. \textbf  {B:} Both episodic accuracy and T-scores are recorded on 60,000 episodes (600 episodes per split). Episodes are grouped into three bins by their T-scores. \textbf  {C:} Performance of training or finetuning on training attributes correlates with T-score. Error bars are standard errors in each bin.\relax }}{13}{figure.caption.22}\protected@file@percent }
\newlabel{fig:transfer}{{5}{13}{\looseness =-10000 \textbf {Few-shot performance vs. transferability across training and test attributes.} \textbf {A:} Transferability score (T-score) is computed based on the AUC of a test attribute predicted by a logistic regression model on a set of training attributes. 100 different random splits across train/test attributes per split are used. \textbf {B:} Both episodic accuracy and T-scores are recorded on 60,000 episodes (600 episodes per split). Episodes are grouped into three bins by their T-scores. \textbf {C:} Performance of training or finetuning on training attributes correlates with T-score. Error bars are standard errors in each bin.\relax }{figure.caption.22}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusion}{14}{section.0.6}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Limitations:}{14}{section*.24}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Societal Impact:}{14}{section*.25}\protected@file@percent }
\bibdata{ref}
\bibcite{labelembed}{{1}{2013}{{Akata et~al.}}{{Akata, Perronnin, Harchaoui, and Schmid}}}
\bibcite{evaluateoutput}{{2}{2015}{{Akata et~al.}}{{Akata, Reed, Walter, Lee, and Schiele}}}
\bibcite{alfassy2019laso}{{3}{2019}{{Alfassy et~al.}}{{Alfassy, Karlinsky, Aides, Shtok, Harary, Feris, Giryes, and Bronstein}}}
\bibcite{amit2018meta}{{4}{2018}{{Amit and Meir}}{{}}}
\bibcite{arnold2021embedding}{{5}{2021}{{Arnold and Sha}}{{}}}
\bibcite{descriptionzsl}{{6}{2015}{{Ba et~al.}}{{Ba, Swersky, Fidler, and Salakhutdinov}}}
\bibcite{baxter2000model}{{7}{2000}{{Baxter}}{{}}}
\bibcite{ben2008notion}{{8}{2008}{{Ben-David and Borbely}}{{}}}
\bibcite{ben2010theory}{{9}{2010}{{Ben-David et~al.}}{{Ben-David, Blitzer, Crammer, Kulesza, Pereira, and Vaughan}}}
\bibcite{simclr}{{10}{2020}{{Chen et~al.}}{{Chen, Kornblith, Norouzi, and Hinton}}}
\bibcite{closerlook}{{11}{2019}{{Chen et~al.}}{{Chen, Liu, Kira, Wang, and Huang}}}
\bibcite{deng2009imagenet}{{12}{2009}{{Deng et~al.}}{{Deng, Dong, Socher, Li, Li, and Fei-Fei}}}
\bibcite{farhadi2009describe}{{13}{2009}{{Farhadi et~al.}}{{Farhadi, Endres, Hoiem, and Forsyth}}}
\bibcite{farhadi2010attribute}{{14}{2010}{{Farhadi et~al.}}{{Farhadi, Endres, and Hoiem}}}
\bibcite{fei2006one}{{15}{2006}{{Fei-Fei et~al.}}{{Fei-Fei, Fergus, and Perona}}}
\bibcite{ferrari2007attribute}{{16}{2007}{{Ferrari and Zisserman}}{{}}}
\bibcite{maml}{{17}{2017}{{Finn et~al.}}{{Finn, Abbeel, and Levine}}}
\bibcite{broadstudy}{{18}{2020}{{Guo et~al.}}{{Guo, Codella, Karlinsky, Smith, Rosing, and Feris}}}
\bibcite{resnet}{{19}{2016}{{He et~al.}}{{He, Zhang, Ren, and Sun}}}
\bibcite{koh2020concept}{{20}{2020}{{Koh et~al.}}{{Koh, Nguyen, Tang, Mussmann, Pierson, Kim, and Liang}}}
\bibcite{lake2011oneshot}{{21}{2011}{{Lake et~al.}}{{Lake, Salakhutdinov, Gross, and Tenenbaum}}}
\bibcite{attributezsl}{{22}{2014}{{Lampert et~al.}}{{Lampert, Nickisch, and Harmeling}}}
\bibcite{li2021compositional}{{23}{2021}{{Li et~al.}}{{Li, Mozer, and Whitehill}}}
\bibcite{celeba}{{24}{2015}{{Liu et~al.}}{{Liu, Luo, Wang, and Tang}}}
\bibcite{lucas2020lb}{{25}{2021}{{Lucas et~al.}}{{Lucas, Ren, Kameni, Pitassi, and Zemel}}}
\bibcite{czsl}{{26}{2017}{{Misra et~al.}}{{Misra, Gupta, and Hebert}}}
\bibcite{tadam}{{27}{2018}{{Oreshkin et~al.}}{{Oreshkin, L{\'{o}}pez, and Lacoste}}}
\bibcite{patterson2016coco}{{28}{2016}{{Patterson and Hays}}{{}}}
\bibcite{pentina2014}{{29}{2014}{{Pentina and Lampert}}{{}}}
\bibcite{pham2021attribute}{{30}{2021}{{Pham et~al.}}{{Pham, Kafle, Lin, Ding, Cohen, Tran, and Shrivastava}}}
\bibcite{taskdriven}{{31}{2019}{{Purushwalkam et~al.}}{{Purushwalkam, Nickel, Gupta, and Ranzato}}}
\bibcite{anil}{{32}{2020}{{Raghu et~al.}}{{Raghu, Raghu, Bengio, and Vinyals}}}
\bibcite{fewshotssl}{{33}{2018}{{Ren et~al.}}{{Ren, Triantafillou, Ravi, Snell, Swersky, Tenenbaum, Larochelle, and Zemel}}}
\bibcite{ezzsl}{{34}{2015}{{Romera{-}Paredes and Torr}}{{}}}
\bibcite{roschmervis1975family}{{35}{1975}{{Rosch and Mervis}}{{}}}
\bibcite{sariyildiz2021}{{36}{2021}{{Sariyildiz et~al.}}{{Sariyildiz, Kalantidis, Larlus, and Alahari}}}
\bibcite{protonet}{{37}{2017}{{Snell et~al.}}{{Snell, Swersky, and Zemel}}}
\bibcite{Thrun1998}{{38}{1998}{{Thrun}}{{}}}
\bibcite{tokmakov2019learning}{{39}{2019}{{Tokmakov et~al.}}{{Tokmakov, Wang, and Hebert}}}
\bibcite{triantafillou2019meta}{{40}{2020}{{Triantafillou et~al.}}{{Triantafillou, Zhu, Dumoulin, Lamblin, Xu, Goroshin, Gelada, Swersky, Manzagol, and Larochelle}}}
\bibcite{matchingnet}{{41}{2016}{{Vinyals et~al.}}{{Vinyals, Blundell, Lillicrap, Kavukcuoglu, and Wierstra}}}
\bibcite{wang2019survey}{{42}{2019{a}}{{Wang et~al.}}{{Wang, Zheng, Yu, and Miao}}}
\bibcite{taskaware}{{43}{2019{b}}{{Wang et~al.}}{{Wang, Yu, Darrell, and Gonzalez}}}
\bibcite{tafenet}{{44}{2019{c}}{{Wang et~al.}}{{Wang, Yu, Wang, Darrell, and Gonzalez}}}
\bibcite{wang2010discriminative}{{45}{2010}{{Wang and Mori}}{{}}}
\bibcite{cub}{{46}{2010}{{Welinder et~al.}}{{Welinder, Branson, Mita, Wah, Schroff, Belongie, and Perona}}}
\bibcite{goodbadugly}{{47}{2019}{{Xian et~al.}}{{Xian, Lampert, Schiele, and Akata}}}
\bibcite{xiang2019incremental}{{48}{2019}{{Xiang et~al.}}{{Xiang, Jin, Ding, Han, and Li}}}
\bibcite{unseencomposition}{{49}{2020}{{Yang et~al.}}{{Yang, Deng, Yan, Liu, and Tao}}}
\bibcite{zappos}{{50}{2014}{{Yu and Grauman}}{{}}}
\bibcite{cam}{{51}{2016}{{Zhou et~al.}}{{Zhou, Khosla, Lapedriza, Oliva, and Torralba}}}
\@writefile{lot}{\contentsline {table}{\numberline {9}{\ignorespaces \textbf  {Celeb-A attribute readout} performance of different representations, measured in mean AUC. RND denotes using a randomly initialized CNN; PN denotes ProtoNet.\relax }}{20}{table.caption.29}\protected@file@percent }
\newlabel{tab:attrreadout}{{9}{20}{\textbf {Celeb-A attribute readout} performance of different representations, measured in mean AUC. RND denotes using a randomly initialized CNN; PN denotes ProtoNet.\relax }{table.caption.29}{}}
\@writefile{lot}{\contentsline {table}{\numberline {10}{\ignorespaces \textbf  {Effect of the L1 regularizer} on different representations for the validation set of Celeb-A 20-shot.\relax }}{20}{table.caption.30}\protected@file@percent }
\newlabel{tab:l1}{{10}{20}{\textbf {Effect of the L1 regularizer} on different representations for the validation set of Celeb-A 20-shot.\relax }{table.caption.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A}Attribute Readout}{20}{section.0.A}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {B}Ablation studies}{20}{section.0.B}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {C}Additional heatmap visualization}{20}{section.0.C}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {11}{\ignorespaces ImageNet-with-Attributes attribute readout binary prediction performance of different representations, measured in mean AUC. \relax }}{20}{table.caption.31}\protected@file@percent }
\newlabel{tab:attrreadout-imageneta}{{11}{20}{ImageNet-with-Attributes attribute readout binary prediction performance of different representations, measured in mean AUC. \relax }{table.caption.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Additional visualization results, on 20-shot episodes, including more methods for comparison.\relax }}{21}{figure.caption.32}\protected@file@percent }
\newlabel{fig:additional_combo}{{6}{21}{Additional visualization results, on 20-shot episodes, including more methods for comparison.\relax }{figure.caption.32}{}}
\@writefile{lot}{\contentsline {table}{\numberline {12}{\ignorespaces Attribute Splits for Celeb-A\relax }}{21}{table.caption.35}\protected@file@percent }
\newlabel{tab:celebasplit}{{12}{21}{Attribute Splits for Celeb-A\relax }{table.caption.35}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D}Attribute splits of Celeb-A}{21}{section.0.D}\protected@file@percent }
\newlabel{app:split}{{D}{21}{Attribute splits of Celeb-A}{section.0.D}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {Visualization of Celeb-A 20-shot LR classifiers using CAM on top of UFTA representations.} Context attributes that define the episode are shown above. Classifier sigmoid confidence scores are shown at the bottom. Red numbers denote wrong classification and green denote correct. \relax }}{22}{figure.caption.33}\protected@file@percent }
\newlabel{fig:celeb-a-additional}{{7}{22}{\textbf {Visualization of Celeb-A 20-shot LR classifiers using CAM on top of UFTA representations.} Context attributes that define the episode are shown above. Classifier sigmoid confidence scores are shown at the bottom. Red numbers denote wrong classification and green denote correct. \relax }{figure.caption.33}{}}
\@writefile{toc}{\contentsline {section}{\numberline {E}Attribute splits of Zappos-50K}{22}{section.0.E}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces \textbf  {Visualization of Zappos-50K 20-shot LR classifiers using CAM on top of UFTA representations.} Context attributes that define the episode are shown above. Classifier sigmoid confidence scores are shown at the bottom. Red numbers denote wrong classification and green denote correct. \relax }}{23}{figure.caption.34}\protected@file@percent }
\newlabel{fig:zappos-additional}{{8}{23}{\textbf {Visualization of Zappos-50K 20-shot LR classifiers using CAM on top of UFTA representations.} Context attributes that define the episode are shown above. Classifier sigmoid confidence scores are shown at the bottom. Red numbers denote wrong classification and green denote correct. \relax }{figure.caption.34}{}}
\@writefile{toc}{\contentsline {section}{\numberline {F}Attribute splits of ImageNet-with-Attributes}{23}{section.0.F}\protected@file@percent }
\newlabel{app:imageneta-split}{{F}{23}{Attribute splits of ImageNet-with-Attributes}{section.0.F}{}}
\@writefile{toc}{\contentsline {section}{\numberline {G}Few-Shot Attribute Learning Toy Problem}{23}{section.0.G}\protected@file@percent }
\newlabel{app:toy_problem}{{G}{23}{Few-Shot Attribute Learning Toy Problem}{section.0.G}{}}
\@writefile{lot}{\contentsline {table}{\numberline {13}{\ignorespaces Attribute splits for Zappos-50K\relax }}{24}{table.caption.36}\protected@file@percent }
\newlabel{tab:zappossplit}{{13}{24}{Attribute splits for Zappos-50K\relax }{table.caption.36}{}}
\@writefile{lot}{\contentsline {table}{\numberline {14}{\ignorespaces Attribute Splits for ImageNet-with-Attributes\relax }}{24}{table.caption.37}\protected@file@percent }
\newlabel{tab:imageneta-split}{{14}{24}{Attribute Splits for ImageNet-with-Attributes\relax }{table.caption.37}{}}
\@writefile{toc}{\contentsline {paragraph}{Problem setup}{24}{section*.38}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Linear prototypical network}{24}{section*.40}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Projecting data features into prototypical network embedding space ($WA$) for the linear toy problem. Values closer to zero are darker in colour. On the FSAL task, the model destroys information from the test attributes to remove ambiguity at training time.\relax }}{25}{figure.caption.39}\protected@file@percent }
\newlabel{fig:toy_problem_weights}{{9}{25}{Projecting data features into prototypical network embedding space ($WA$) for the linear toy problem. Values closer to zero are darker in colour. On the FSAL task, the model destroys information from the test attributes to remove ambiguity at training time.\relax }{figure.caption.39}{}}
\@writefile{toc}{\contentsline {paragraph}{Fitting the prototypical network}{25}{section*.41}\protected@file@percent }
\@writefile{toc}{\contentsline {paragraph}{Settings for Figure\nobreakspace  {}\ref {fig:toy_problem_weights}}{26}{section*.42}\protected@file@percent }
\newlabel{jmlrend}{{G}{26}{end of }{section*.43}{}}
\gdef \@abspage@last{26}

\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{vrp}
\citation{vrp}
\citation{concorde,lkh3}
\citation{pointer,combinatorialgraph,am,ean}
\newlabel{intro}{{1}{1}{}{section.1}{}}
\newlabel{fig:teaser}{{1}{1}{A visualization of the route produced by a fleet of twenty vehicles using our proposed algorithm. Colors denote different vehicle trajectories}{figure.1}{}}
\citation{macroscopicsim,continuum}
\citation{lkh3}
\citation{am,ean,gvin}
\citation{concorde,branchandcut,lkh3}
\citation{spreadsheetvrp,gavrp,ilpvrp}
\citation{pointer,transformer}
\citation{gcn,combinatorialgraph}
\citation{marl,coopmasvrp,masterslave}
\citation{am,ean}
\citation{pointer,onlineroutenn}
\citation{ean}
\citation{am}
\citation{vin}
\citation{bellman}
\citation{gppn}
\citation{lstm}
\citation{gvin}
\citation{gnn,gnnsurvey}
\citation{gcn}
\citation{ggnn}
\citation{gtn,gat}
\citation{am}
\citation{ean}
\citation{dynamicroute,maretrieval,commefficiency}
\citation{commnet}
\citation{commnet,coop,attcomm}
\citation{commnet}
\citation{attcomm}
\citation{emergence,multiagentrl}
\citation{graphpolicygrad}
\citation{macontrol}
\newlabel{tab:notation}{{1}{3}{Notation}{table.1}{}}
\citation{gvin}
\citation{gtn}
\newlabel{fig:mainfig}{{2}{4}{\textbf {Our proposed multi-agent routing value iteration network}: \textbf {A)} The map is represented as a graph and each node has some local observation features; \textbf {B)} Each agent operates its own value iteration network. It uses an attention-based LSTM on each graph node to exchange information. The LSTM runs for $k$ iterations and can be decoded into a value function for selecting next destination. \textbf {C)} Inter-agent communication is implemented with an attention mechanism over all the incoming messages, and the output is fed as additional channels of inputs to the value iteration module}{figure.2}{}}
\newlabel{tab:node_feature}{{2}{4}{Graph input feature representation for node $v$}{table.2}{}}
\citation{reinforce}
\citation{macroscopicsim}
\citation{continuum}
\newlabel{tab:stats}{{3}{6}{Realistic autonomous mapping benchmark statistics}{table.3}{}}
\citation{lkh3}
\citation{gvin}
\citation{gat}
\citation{am}
\citation{ean}
\newlabel{fig:scalability}{{3}{7}{Number of agents performing traversal and corresponding cost of the traversal (trained using RL)}{figure.3}{}}
\newlabel{tab:1}{{4}{7}{Average graph traversal cost on realistic graphs; Time cost in hours; Runtime in milliseconds}{table.4}{}}
\newlabel{fig:all}{{4}{8}{\textbf {(a) IL vs. RL:} Comparison of imitation learning and reinforcement learning on different number of agents; \textbf {(b) Runtime:} Comparison MARVIN's runtime to that of the LKH solver; \textbf {(c) No. iterations in the VIN module:} Evaluation of how the number of value iterations has on performance, and how the number of iterations generally scales for other value iteration models (GVIN); \textbf {(d) Communication module design:} Comparison of our communication protocol to other communication protocol alternatives}{figure.4}{}}
\newlabel{fig:retrained}{{5}{8}{The average traversal time (hrs) relative to the number of nodes in the graph for policies trained exclusively on 25 node graphs and 100 node graphs}{figure.5}{}}
\citation{am}
\citation{am}
\bibdata{marvin}
\newlabel{tab:multipass}{{5}{9}{Model performance on different multi-pass distributions}{table.5}{}}
\newlabel{tab:toy}{{6}{9}{Single agent TSP on synthetic graphs of size 25. We abbreviate methods that make use of \emph {self-starting} with \textbf {SS} and \emph {sampling} with \textbf {SP}}{table.6}{}}
\newlabel{tab:accuracy}{{7}{9}{Action prediction accuracy on different value iteration module designs. All models are trained using imitation learning}{table.7}{}}
\bibcite{concorde}{{1}{2006}{{Applegate et~al.}}{{Applegate, Bixby, Chvatal, and Cook}}}
\bibcite{maretrieval}{{2}{1993}{{Arkin et~al.}}{{Arkin, Balch, and Nitz}}}
\bibcite{gavrp}{{3}{2007}{{Bae et~al.}}{{Bae, Hwang, Cho, and Goan}}}
\bibcite{coopmasvrp}{{4}{2012}{{Barbucha}}{{}}}
\bibcite{bellman}{{5}{1954}{{Bellman}}{{}}}
\bibcite{commefficiency}{{6}{2004}{{Berna-Koes et~al.}}{{Berna-Koes, Nourbakhsh, and Sycara}}}
\bibcite{ean}{{7}{2018}{{Deudon et~al.}}{{Deudon, Cournut, Lacoste, Adulyasak, and Rousseau}}}
\bibcite{spreadsheetvrp}{{8}{2017}{{Erdogan}}{{}}}
\bibcite{branchandcut}{{9}{2003}{{Fischetti et~al.}}{{Fischetti, Lodi, and Toth}}}
\bibcite{macontrol}{{10}{2017}{{Gupta et~al.}}{{Gupta, Egorov, and Kochenderfer}}}
\bibcite{lkh3}{{11}{2017}{{Helsgaun}}{{}}}
\bibcite{lstm}{{12}{1997}{{Hochreiter \& Schmidhuber}}{{Hochreiter and Schmidhuber}}}
\bibcite{attcomm}{{13}{2018}{{Jiang \& Lu}}{{Jiang and Lu}}}
\bibcite{combinatorialgraph}{{14}{2017}{{Khalil et~al.}}{{Khalil, Dai, Zhang, Dilkina, and Song}}}
\bibcite{graphpolicygrad}{{15}{2019}{{Khan et~al.}}{{Khan, Tolstaya, Ribeiro, and Kumar}}}
\bibcite{gcn}{{16}{2017}{{Kipf \& Welling}}{{Kipf and Welling}}}
\bibcite{coop}{{17}{2012}{{Kobayashi et~al.}}{{Kobayashi, Kurano, Kuremoto, and Obayashi}}}
\bibcite{masterslave}{{18}{2017}{{Kong et~al.}}{{Kong, Xin, Liu, and Wang}}}
\bibcite{am}{{19}{2019}{{Kool et~al.}}{{Kool, van Hoof, and Welling}}}
\bibcite{gppn}{{20}{2018}{{Lee et~al.}}{{Lee, Parisotto, Chaplot, Xing, and Salakhutdinov}}}
\bibcite{ggnn}{{21}{2016}{{Li et~al.}}{{Li, Tarlow, Brockschmidt, and Zemel}}}
\bibcite{emergence}{{22}{2005}{{McPartland et~al.}}{{McPartland, Nolfi, and Abbass}}}
\bibcite{ilpvrp}{{23}{2017}{{Montero et~al.}}{{Montero, Bront, and M{\'{e}}ndez{-}D{\'{\i }}az}}}
\bibcite{gvin}{{24}{2018}{{Niu et~al.}}{{Niu, Chen, Guo, Targonski, Smith, and Kovacevic}}}
\bibcite{dynamicroute}{{25}{2010}{{Pavone}}{{}}}
\bibcite{gnn}{{26}{2009}{{Scarselli et~al.}}{{Scarselli, Gori, Tsoi, Hagenbuchner, and Monfardini}}}
\bibcite{continuum}{{27}{2010}{{Sewall et~al.}}{{Sewall, Wilkie, Merrell, and Lin}}}
\bibcite{commnet}{{28}{2016}{{Sukhbaatar et~al.}}{{Sukhbaatar, Szlam, and Fergus}}}
\bibcite{vin}{{29}{2016}{{Tamar et~al.}}{{Tamar, Levine, Abbeel, Wu, and Thomas}}}
\bibcite{macroscopicsim}{{30}{2011}{{Tamp{\`e}re et~al.}}{{Tamp{\`e}re, Corthout, Cattrysse, and Immers}}}
\bibcite{multiagentrl}{{31}{1993}{{Tan}}{{}}}
\bibcite{vrp}{{32}{2002}{{Toth \& Vigo}}{{Toth and Vigo}}}
\bibcite{transformer}{{33}{2017}{{Vaswani et~al.}}{{Vaswani, Shazeer, Parmar, Uszkoreit, Jones, Gomez, Kaiser, and Polosukhin}}}
\bibcite{gat}{{34}{2018}{{Velickovic et~al.}}{{Velickovic, Cucurull, Casanova, Romero, Li{\`{o}}, and Bengio}}}
\bibcite{pointer}{{35}{2015}{{Vinyals et~al.}}{{Vinyals, Fortunato, and Jaitly}}}
\bibcite{reinforce}{{36}{1992}{{Williams}}{{}}}
\bibcite{gnnsurvey}{{37}{2019}{{Wu et~al.}}{{Wu, Pan, Chen, Long, Zhang, and Yu}}}
\bibcite{onlineroutenn}{{38}{2019}{{Yu et~al.}}{{Yu, Yu, and Gu}}}
\bibcite{gtn}{{39}{2019}{{Yun et~al.}}{{Yun, Jeong, Kim, Kang, and Kim}}}
\bibcite{marl}{{40}{2014}{{Zolfpour-Arokhlo et~al.}}{{Zolfpour-Arokhlo, Selamat, Hashim, and Afkhami}}}
\bibstyle{icml2020}
\newlabel{fig:heatmap_cluster}{{6}{13}{Value function of an agents while mapping a given region. The value function is high around the roads that are close to the agent in a sense that implies that this cluster has been assigned to that agent. The red dot on the left and the blue dot on the right represent the agent's current position}{figure.6}{}}
\newlabel{fig:heatmap_sporadic}{{7}{13}{Value function of an agents while mapping a given region. The value function is high around the roads that are distant and sporadically distributed implying an exploratory strategy. The red dot on the left and the blue dot on the right represent the agent's current position}{figure.7}{}}
\newlabel{fig:vin_gvin}{{8}{13}{Bird's eye view of a partially complete traversal of MARVIN (left) and of the GVIN (right). While slightly more spread out, the traversal of the GVIN leaves many small streets unvisited and is less thorough overall}{figure.8}{}}
\newlabel{fig:il_rl}{{9}{14}{Bird's eye view of a partially complete traversal of MARVIN trained with RL (left) and MARVIN trained with IL (right). Both are relatively thorough while expanding to new regions, but the model trained using imitation learning is able to cover the regions in a more efficient manner}{figure.9}{}}
\newlabel{fig:example_graphs}{{10}{14}{Random graphs sampled from the training set}{figure.10}{}}
\gdef \@abspage@last{14}

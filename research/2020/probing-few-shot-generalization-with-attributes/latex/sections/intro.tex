% !TEX root = ../icml2022.tex

% \savespacebeforesection
%\savespacebeforesection
\savespacebeforesection
%\section{Introduction}
% \savespacebeforesection

\section{Introduction}
\savespacebeforesection
Formation of class concepts is one of the most fundamental processes in machine
perception. Although class concepts are often defined based on their attribute
information, \eg, \emph{birds} are warm-blooded vertebrates that lay eggs and
have feathers, attributes are rarely considered in a typical machine perception
system that directly maps from input signals to output classes. Humans also
leverage similarity in the attribute space to recognize classes, which are
``\emph{information-rich bundles of attributes that form natural
discontinuities}''~\citep{roschmervis1975family}. The acquisition of attribute
knowledge therefore helps us build a more compact and efficient representation
that is useful for the perception of classes.
Another distinct advantage of using attribute information is that it
facilitates learning new classes with few or even zero examples, which has been
leveraged in studies of zero-shot learning (ZSL)~\citep{zsl,attributezsl,czsl}.
Other models use attributes as direct outputs before the classes for improved
modularity and interpretability~\citep{farhadi2009describe,koh2020concept}. 

% \JL{Some paragraphs were wrapped with an \textbackslash ignore environment that threw errors. Commented these out.}

% \ignore{
% However, all of these attribute-based models rely on a pre-defined set of
% attributes, that are shared among all classes. Consider a learning agent
% deployed in the wild. Although the agent may learn new classes by composing
% some of the existing attributes, its learning capability would be greatly
% improved if it can expand its attribute vocabulary.

% Motivated by this learning scenario, we are interested in the problem of
% learning new attributes that are previously not labeled in the dataset. This is
% a step towards continual learning~\citep{van2019three}, where the reward
% function evolves and the system must adapt if the reward becomes dependent on
% previously irrelevant input attributes. In particular, we focus on a few-shot
% learning (FSL) setup~\citep{lake2011oneshot,matchingnet}, where only a few
% positive and negative examples of the target attributes are available, to model
% the rapid adaptation task.

% \looseness=-1000
% }
In this work, we utilize attribute information to gain insight into few-shot classification, and into what underlies the ability to 
generalize better to some novel classes than others.
Classes rely on features or attributes, and if novel classes rely on attributes that were relevant for training classes, albeit different combinations, then it seems natural that novel classes
can be readily recognized with just a few labeled examples. But what if novel classes rely on features that were not relevant for training classes? Will these classes be hard to learn?

Earlier studies have examined the difficulty of few-shot learning of particular classes, based on
datasets with a class hierarchy (like ImageNet), or other notions of similarity, like similarity of classes in the features space of pre-trained models [1], or similarity in terms of task embeddings [2].
Here we propose a more controlled study of few-shot generalization. We create a few-shot paradigm, which
we call \titlelower{} (\taskname{}),
that explicitly relies on attributes, and 
focuses on attributes which were not relevant for classes in the training set.
Since semantic classes can often be defined
with a set of attributes, a split in the attribute space therefore provides us
a finer control on the degree to which training classes are \emph{related} to
test ones.

% \ignore{
% Considering few-shot attribute learning has an extra benefit, in that it can
% provide manipulable factors to study generalization. In standard few-shot
% learning, object semantic classes are split into training and test; however,
% there is still a lack of understanding of when models transfer their knowledge
% from training classes to test ones. Since semantic classes can often be defined
% with a set of attributes, a split in the attribute space therefore provides us
% a finer control on the degree to which training classes are \emph{related} to
% test ones. By studying the transfer performance on novel attributes, we expect
% our work can generate insight into the generalization performance on semantic
% classes in standard few-shot learning.
% }

To study this challenging task of %\titlelower{} (\taskname{})
\taskname{} we contribute
new benchmark datasets consisting of images of faces (Celeb-A)~\citep{celeba},
shoes (Zappos50K)~\citep{zappos}, and general objects
(ImageNet-with-Attributes)~\citep{deng2009imagenet}. 

We examine the performance of different approaches to learning in this paradigm: a supervised approach, which pre-trains on classes or directly on attributes;
an unsupervised approach, and a hybrid of the two, which fine-tunes an unsupervised representation using attribute information. Unlike in standard
few-shot learning where supervised pre-training generally helps learning,
surprisingly we found that directly supervising the model with a set of
training attributes does not generalize well on the test attributes, whereas
self-supervised pre-training brings significant improvement. 
We further ran
experiments with random splits of the attribute space and discovered that the
predictability of attributes provides an informative estimate of a model's
ability to generalize. The few-shot attribute learning paradigm proposed in
this paper will facilitate more efficient and flexible continual learning and
shed a light on the practical understanding on generalization of novel
concepts. \JL{Worth discussing insights into self-supervised learning vs. others? Maybe a challenge to sell with only SimCLR.}

Our primary contributions are:
1. a new paradigm for studying generalization in few-shot learning; 2. new datasets for examining this; 3. show and analyze why particular representation learning works best.

% \MR{Novel setup, findings, don't say it's a novel method. Empirical study. Not exactly unsupervised, not exactly supervised, but a combination. Why is it surprising tidy up the experiments. Better understand few-shot discovery. and our hypothesis is that classes rely on attributes and features and novel classes rely on }

% \RZ{Another thought was that we should not say we have "Our" methods, but rather pitch it as an empirical paper, comparing supervised and self-supervised representation learning, and a hybrid unsupervised with supervised fine-tuning. Maybe avoid "not novel" criticism.
% Somewhat surprising finding fine-tuning improves unsupervised, given that test episodes involve novel attributes. We
% do further analysis why - uncover potential explanation, based on the relationship between training and test attributes.
% }


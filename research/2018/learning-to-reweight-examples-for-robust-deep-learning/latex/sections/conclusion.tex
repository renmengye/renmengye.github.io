% !TEX root = ../main.tex

\section{Conclusion}
In this work, we propose an online meta-learning algorithm for reweighting training examples and
training more robust deep learning models. While various types of training set biases exist and
manually designed reweighting objectives have their own bias, our automatic reweighting algorithm
shows superior performance dealing with class imbalance, noisy labels, and both. Our method can be
directly applied to any deep learning architecture and is expected to train end-to-end without any
additional hyperparameter search. Validating on every training step is a novel setting and we show
that it has links with model regularization, which can be a fruitful future research direction.

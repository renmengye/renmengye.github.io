<!DOCTYPE html><html><head>
<title>SBNet: Sparse Blocks Network for Fast Inference</title>
<!--Generated by LaTeXML (version 0.8.4) http://dlmf.nist.gov/LaTeXML/.-->

<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="index.css" type="text/css">

<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><style type="text/css">.mjx-chtml {display: inline-block; line-height: 0; text-indent: 0; text-align: left; text-transform: none; font-style: normal; font-weight: normal; font-size: 100%; font-size-adjust: none; letter-spacing: normal; word-wrap: normal; word-spacing: normal; white-space: nowrap; float: none; direction: ltr; max-width: none; max-height: none; min-width: 0; min-height: 0; border: 0; margin: 0; padding: 1px 0}
.MJXc-display {display: block; text-align: center; margin: 1em 0; padding: 0}
.mjx-chtml[tabindex]:focus, body :focus .mjx-chtml[tabindex] {display: inline-table}
.mjx-full-width {text-align: center; display: table-cell!important; width: 10000em}
.mjx-math {display: inline-block; border-collapse: separate; border-spacing: 0}
.mjx-math * {display: inline-block; -webkit-box-sizing: content-box!important; -moz-box-sizing: content-box!important; box-sizing: content-box!important; text-align: left}
.mjx-numerator {display: block; text-align: center}
.mjx-denominator {display: block; text-align: center}
.MJXc-stacked {height: 0; position: relative}
.MJXc-stacked > * {position: absolute}
.MJXc-bevelled > * {display: inline-block}
.mjx-stack {display: inline-block}
.mjx-op {display: block}
.mjx-under {display: table-cell}
.mjx-over {display: block}
.mjx-over > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-under > * {padding-left: 0px!important; padding-right: 0px!important}
.mjx-stack > .mjx-sup {display: block}
.mjx-stack > .mjx-sub {display: block}
.mjx-prestack > .mjx-presup {display: block}
.mjx-prestack > .mjx-presub {display: block}
.mjx-delim-h > .mjx-char {display: inline-block}
.mjx-surd {vertical-align: top}
.mjx-mphantom * {visibility: hidden}
.mjx-merror {background-color: #FFFF88; color: #CC0000; border: 1px solid #CC0000; padding: 2px 3px; font-style: normal; font-size: 90%}
.mjx-annotation-xml {line-height: normal}
.mjx-menclose > svg {fill: none; stroke: currentColor}
.mjx-mtr {display: table-row}
.mjx-mlabeledtr {display: table-row}
.mjx-mtd {display: table-cell; text-align: center}
.mjx-label {display: table-row}
.mjx-box {display: inline-block}
.mjx-block {display: block}
.mjx-span {display: inline}
.mjx-char {display: block; white-space: pre}
.mjx-itable {display: inline-table; width: auto}
.mjx-row {display: table-row}
.mjx-cell {display: table-cell}
.mjx-table {display: table; width: 100%}
.mjx-line {display: block; height: 0}
.mjx-strut {width: 0; padding-top: 1em}
.mjx-vsize {width: 0}
.MJXc-space1 {margin-left: .167em}
.MJXc-space2 {margin-left: .222em}
.MJXc-space3 {margin-left: .278em}
.mjx-test.mjx-test-display {display: table!important}
.mjx-test.mjx-test-inline {display: inline!important; margin-right: -1px}
.mjx-test.mjx-test-default {display: block!important; clear: both}
.mjx-ex-box {display: inline-block!important; position: absolute; overflow: hidden; min-height: 0; max-height: none; padding: 0; border: 0; margin: 0; width: 1px; height: 60ex}
.mjx-test-inline .mjx-left-box {display: inline-block; width: 0; float: left}
.mjx-test-inline .mjx-right-box {display: inline-block; width: 0; float: right}
.mjx-test-display .mjx-right-box {display: table-cell!important; width: 10000em!important; min-width: 0; max-width: none; padding: 0; border: 0; margin: 0}
.MJXc-TeX-unknown-R {font-family: monospace; font-style: normal; font-weight: normal}
.MJXc-TeX-unknown-I {font-family: monospace; font-style: italic; font-weight: normal}
.MJXc-TeX-unknown-B {font-family: monospace; font-style: normal; font-weight: bold}
.MJXc-TeX-unknown-BI {font-family: monospace; font-style: italic; font-weight: bold}
.MJXc-TeX-ams-R {font-family: MJXc-TeX-ams-R,MJXc-TeX-ams-Rw}
.MJXc-TeX-cal-B {font-family: MJXc-TeX-cal-B,MJXc-TeX-cal-Bx,MJXc-TeX-cal-Bw}
.MJXc-TeX-frak-R {font-family: MJXc-TeX-frak-R,MJXc-TeX-frak-Rw}
.MJXc-TeX-frak-B {font-family: MJXc-TeX-frak-B,MJXc-TeX-frak-Bx,MJXc-TeX-frak-Bw}
.MJXc-TeX-math-BI {font-family: MJXc-TeX-math-BI,MJXc-TeX-math-BIx,MJXc-TeX-math-BIw}
.MJXc-TeX-sans-R {font-family: MJXc-TeX-sans-R,MJXc-TeX-sans-Rw}
.MJXc-TeX-sans-B {font-family: MJXc-TeX-sans-B,MJXc-TeX-sans-Bx,MJXc-TeX-sans-Bw}
.MJXc-TeX-sans-I {font-family: MJXc-TeX-sans-I,MJXc-TeX-sans-Ix,MJXc-TeX-sans-Iw}
.MJXc-TeX-script-R {font-family: MJXc-TeX-script-R,MJXc-TeX-script-Rw}
.MJXc-TeX-type-R {font-family: MJXc-TeX-type-R,MJXc-TeX-type-Rw}
.MJXc-TeX-cal-R {font-family: MJXc-TeX-cal-R,MJXc-TeX-cal-Rw}
.MJXc-TeX-main-B {font-family: MJXc-TeX-main-B,MJXc-TeX-main-Bx,MJXc-TeX-main-Bw}
.MJXc-TeX-main-I {font-family: MJXc-TeX-main-I,MJXc-TeX-main-Ix,MJXc-TeX-main-Iw}
.MJXc-TeX-main-R {font-family: MJXc-TeX-main-R,MJXc-TeX-main-Rw}
.MJXc-TeX-math-I {font-family: MJXc-TeX-math-I,MJXc-TeX-math-Ix,MJXc-TeX-math-Iw}
.MJXc-TeX-size1-R {font-family: MJXc-TeX-size1-R,MJXc-TeX-size1-Rw}
.MJXc-TeX-size2-R {font-family: MJXc-TeX-size2-R,MJXc-TeX-size2-Rw}
.MJXc-TeX-size3-R {font-family: MJXc-TeX-size3-R,MJXc-TeX-size3-Rw}
.MJXc-TeX-size4-R {font-family: MJXc-TeX-size4-R,MJXc-TeX-size4-Rw}
.MJXc-TeX-vec-R {font-family: MJXc-TeX-vec-R,MJXc-TeX-vec-Rw}
.MJXc-TeX-vec-B {font-family: MJXc-TeX-vec-B,MJXc-TeX-vec-Bx,MJXc-TeX-vec-Bw}
@font-face {font-family: MJXc-TeX-ams-R; src: local('MathJax_AMS'), local('MathJax_AMS-Regular')}
@font-face {font-family: MJXc-TeX-ams-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_AMS-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_AMS-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_AMS-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-B; src: local('MathJax_Caligraphic Bold'), local('MathJax_Caligraphic-Bold')}
@font-face {font-family: MJXc-TeX-cal-Bx; src: local('MathJax_Caligraphic'); font-weight: bold}
@font-face {font-family: MJXc-TeX-cal-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-R; src: local('MathJax_Fraktur'), local('MathJax_Fraktur-Regular')}
@font-face {font-family: MJXc-TeX-frak-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-frak-B; src: local('MathJax_Fraktur Bold'), local('MathJax_Fraktur-Bold')}
@font-face {font-family: MJXc-TeX-frak-Bx; src: local('MathJax_Fraktur'); font-weight: bold}
@font-face {font-family: MJXc-TeX-frak-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Fraktur-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Fraktur-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Fraktur-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-BI; src: local('MathJax_Math BoldItalic'), local('MathJax_Math-BoldItalic')}
@font-face {font-family: MJXc-TeX-math-BIx; src: local('MathJax_Math'); font-weight: bold; font-style: italic}
@font-face {font-family: MJXc-TeX-math-BIw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-BoldItalic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-BoldItalic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-BoldItalic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-R; src: local('MathJax_SansSerif'), local('MathJax_SansSerif-Regular')}
@font-face {font-family: MJXc-TeX-sans-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-B; src: local('MathJax_SansSerif Bold'), local('MathJax_SansSerif-Bold')}
@font-face {font-family: MJXc-TeX-sans-Bx; src: local('MathJax_SansSerif'); font-weight: bold}
@font-face {font-family: MJXc-TeX-sans-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-sans-I; src: local('MathJax_SansSerif Italic'), local('MathJax_SansSerif-Italic')}
@font-face {font-family: MJXc-TeX-sans-Ix; src: local('MathJax_SansSerif'); font-style: italic}
@font-face {font-family: MJXc-TeX-sans-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_SansSerif-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_SansSerif-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_SansSerif-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-script-R; src: local('MathJax_Script'), local('MathJax_Script-Regular')}
@font-face {font-family: MJXc-TeX-script-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Script-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Script-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Script-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-type-R; src: local('MathJax_Typewriter'), local('MathJax_Typewriter-Regular')}
@font-face {font-family: MJXc-TeX-type-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Typewriter-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Typewriter-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Typewriter-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-cal-R; src: local('MathJax_Caligraphic'), local('MathJax_Caligraphic-Regular')}
@font-face {font-family: MJXc-TeX-cal-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Caligraphic-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Caligraphic-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Caligraphic-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-B; src: local('MathJax_Main Bold'), local('MathJax_Main-Bold')}
@font-face {font-family: MJXc-TeX-main-Bx; src: local('MathJax_Main'); font-weight: bold}
@font-face {font-family: MJXc-TeX-main-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Bold.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-I; src: local('MathJax_Main Italic'), local('MathJax_Main-Italic')}
@font-face {font-family: MJXc-TeX-main-Ix; src: local('MathJax_Main'); font-style: italic}
@font-face {font-family: MJXc-TeX-main-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-main-R; src: local('MathJax_Main'), local('MathJax_Main-Regular')}
@font-face {font-family: MJXc-TeX-main-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Main-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Main-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Main-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-math-I; src: local('MathJax_Math Italic'), local('MathJax_Math-Italic')}
@font-face {font-family: MJXc-TeX-math-Ix; src: local('MathJax_Math'); font-style: italic}
@font-face {font-family: MJXc-TeX-math-Iw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Math-Italic.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Math-Italic.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Math-Italic.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size1-R; src: local('MathJax_Size1'), local('MathJax_Size1-Regular')}
@font-face {font-family: MJXc-TeX-size1-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size1-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size1-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size1-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size2-R; src: local('MathJax_Size2'), local('MathJax_Size2-Regular')}
@font-face {font-family: MJXc-TeX-size2-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size2-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size2-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size2-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size3-R; src: local('MathJax_Size3'), local('MathJax_Size3-Regular')}
@font-face {font-family: MJXc-TeX-size3-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size3-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size3-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size3-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-size4-R; src: local('MathJax_Size4'), local('MathJax_Size4-Regular')}
@font-face {font-family: MJXc-TeX-size4-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Size4-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Size4-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Size4-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-R; src: local('MathJax_Vector'), local('MathJax_Vector-Regular')}
@font-face {font-family: MJXc-TeX-vec-Rw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Regular.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Regular.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Regular.otf') format('opentype')}
@font-face {font-family: MJXc-TeX-vec-B; src: local('MathJax_Vector Bold'), local('MathJax_Vector-Bold')}
@font-face {font-family: MJXc-TeX-vec-Bx; src: local('MathJax_Vector'); font-weight: bold}
@font-face {font-family: MJXc-TeX-vec-Bw; src /*1*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/eot/MathJax_Vector-Bold.eot'); src /*2*/: url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/woff/MathJax_Vector-Bold.woff') format('woff'), url('https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/fonts/HTML-CSS/TeX/otf/MathJax_Vector-Bold.otf') format('opentype')}
</style></head>
<body>
<div class="ltx_page_main">
<div class="ltx_page_content">
<article class="ltx_document ltx_authors_1line">
<h1 class="ltx_title ltx_title_document">SBNet: Sparse Blocks Network for Fast Inference</h1>
<div class="ltx_authors">
<span class="ltx_creator ltx_role_author">
<span class="ltx_personname">
Mengye Ren<span id="m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="{}^{*,1,2}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"></span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span></span></span>,
Andrei Pokrovsky<span id="m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="{}^{*,1}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"></span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span></span></span>,
Bin Yang<span id="m3" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="{}^{*,1,2}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"></span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.151em; padding-bottom: 0.298em;">∗</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span></span></span>,
Raquel Urtasun<span id="m4" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="{}^{1,2}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"></span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span></span></span>

<br class="ltx_break"><span id="m5" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="{}^{1}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"></span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span></span></span></span></span>Uber Advanced Technologies Group
<br class="ltx_break"><span id="m6" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="{}^{2}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-texatom"><span class="mjx-mrow"></span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span></span></span></span></span>University of Toronto

<br class="ltx_break"><span class="ltx_text ltx_font_typewriter" style="font-size:90%;">{mren3,andrei,byang10,urtasun}@uber.com</span>

<br class="ltx_break">*Equal Contribution.

</span></span>
</div>

<div class="ltx_abstract">
<h6 class="ltx_title ltx_title_abstract">Abstract</h6>
<p class="ltx_p">Conventional deep convolutional neural networks (CNNs) apply convolution operators uniformly in
space across all feature maps for hundreds of layers - this incurs a high computational cost for
real-time applications. For many problems such as object detection and semantic segmentation, we are
able to obtain a low-cost computation mask, either from <span class="ltx_text ltx_font_italic">a priori</span> problem knowledge, or from a
low-resolution segmentation network. We show that such computation masks can be used to reduce
computation in the high-resolution main network. Variants of sparse activation CNNs have previously
been explored on small-scale tasks and showed no degradation in terms of object classification
accuracy, but often measured gains in terms of theoretical FLOPs without realizing a practical
speed-up when compared to highly optimized dense convolution implementations. In this work, we
leverage the sparsity structure of computation masks and propose a novel tiling-based sparse
convolution algorithm. We verified the effectiveness of our sparse CNN on LiDAR-based 3D object
detection, and we report significant wall-clock speed-ups compared to dense convolution without
noticeable loss of accuracy.
<span id="footnote1" class="ltx_note ltx_role_footnote"><sup class="ltx_note_mark">†</sup><span class="ltx_note_outer"><span class="ltx_note_content"><sup class="ltx_note_mark">†</sup>Code available at <a href="https://github.com/uber/sbnet" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://github.com/uber/sbnet</a></span></span></span></p>
</div>
<section id="S1" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">1 </span>Introduction</h2>

<div id="S1.p1" class="ltx_para">
<p class="ltx_p">Deep convolutional neural networks (CNNs) have led to major breakthroughs in many computer vision
tasks <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib16" title="ImageNet classification with deep convolutional neural networks" class="ltx_ref">21</a>]</cite>. While model accuracy consistently improves with the number of
layers <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="Deep residual learning for image recognition" class="ltx_ref">11</a>]</cite>, as current standard networks use over a hundred convolution layers, the amount
of computation involved in deep CNNs can be prohibitively expensive for real-time applications such
as autonomous driving.</p>
</div>
<figure id="S1.F1" class="ltx_figure"><img src="figures/sparse_conv_2.png" id="S1.F1.g1" class="ltx_graphics ltx_centering" width="540" height="233" alt="Our proposed tiled sparse convolution module">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 1: </span>Our proposed tiled sparse convolution module</figcaption>
</figure>
<div id="S1.p2" class="ltx_para">
<p class="ltx_p">Spending equal amount of computation at all spatial locations is a tremendous waste, since spatial
sparsity is ubiquitous in many applications: in autonomous driving, only the areas on the road
matter for object detection; in video segmentation, only occluded and fast-moving pixels require
recomputation; in 3D object classification <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib39" title="3D shapenets: A deep representation for volumetric shapes" class="ltx_ref">34</a>]</cite>, sparsity is directly encoded in the
inputs as voxel occupancy. In these examples, spatial sparsity can be represented as binary
computation masks where ones indicate active locations that need more computation and zeros
inactive. In cases where such masks are not directly available from the inputs, we can predict them
in the form of visual saliency <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib37" title="A model of saliency-based visual attention for rapid scene analysis" class="ltx_ref">16</a>]</cite> or objectness prior <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="RON: reverse connection with objectness prior networks for object detection" class="ltx_ref">20</a>]</cite> by using another
relatively cheap network or even a part of the main network itself
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="Spatially adaptive computation time for residual networks" class="ltx_ref">4</a>, <a href="#bib.bib23" title="Not all pixels are equal: difficulty-aware semantic segmentation via deep layer cascade" class="ltx_ref">25</a>]</cite>.</p>
</div>
<div id="S1.p3" class="ltx_para">
<p class="ltx_p">These binary computation masks can be efficiently incorporated into the computation of deep CNNs:
instead of convolving the input features at every location, we propose to use the masks to guide the
convolutional filters. Computation masks can also be considered as a form of attention mechanism
where the attention weights are binary. While most current uses of attention in computer vision have
been predominantly targeted at better model interpretability and higher prediction accuracy, our
work highlights the benefit of attentional inference speed-up.</p>
</div>
<div id="S1.p4" class="ltx_para">
<p class="ltx_p">In this work, we leverage structured sparsity patterns of computation masks and propose Sparse
Blocks Networks (SBNet), which computes convolution on a blockwise decomposition of the mask. We
implemented our proposed sparse convolution kernels (fragments of parallel code) on graphics
processing unit (GPU) and we report wall-clock time speed-up compared against state-of-the-art GPU
dense convolution implementations. Our algorithm works well with the popular residual network
(ResNet) architectures <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="Deep residual learning for image recognition" class="ltx_ref">11</a>]</cite> and produces further speed-up when integrated within a residual
unit.</p>
</div>
<div id="S1.p5" class="ltx_para">
<p class="ltx_p">Our sparse block unit can serve as a computational module in almost all deep CNNs for various
applications involving sparse regions of interest, bringing inference speed-up without sacrificing
input resolution or model capacity. We evaluate the effectiveness of our SBNet on LiDAR 3D object
detection tasks under a top-down bird’s eye view, and we leverage both static road maps and dynamic
attention maps as our computation masks. We found SBNet achieves significant inference speedup
without noticeable loss of accuracy.

</p>
</div>
</section>
<section id="S2" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">2 </span>Related work</h2>

<div id="S2.p1" class="ltx_para">
<p class="ltx_p">Sparse computation in deep learning has been extensively explored in the weights domain, where the
model size can be significantly reduced through pruning and low-rank decomposition
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib11" title="Speeding up convolutional neural networks with low rank expansions" class="ltx_ref">17</a>, <a href="#bib.bib3" title="Sparse convolutional neural networks" class="ltx_ref">27</a>, <a href="#bib.bib14" title="Learning both weights and connections for efficient neural networks" class="ltx_ref">10</a>, <a href="#bib.bib13" title="Learning structured sparsity in deep neural networks" class="ltx_ref">32</a>, <a href="#bib.bib1" title="Pruning filters for efficient convnets" class="ltx_ref">24</a>, <a href="#bib.bib20" title="Deep roots: improving cnn efficiency with hierarchical filter groups" class="ltx_ref">14</a>]</cite>. However it is not trivial to achieve huge speed-up
from sparse filters without loss of accuracy because a single filter channel is rarely very close
to zero at every point. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib1" title="Pruning filters for efficient convnets" class="ltx_ref">24</a>, <a href="#bib.bib47" title="Channel pruning for accelerating very deep neural networks" class="ltx_ref">12</a>]</cite> explored structured sparsity by
pruning an entire filter. Other forms of redundancies can also be leveraged such as weight
quantization <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib40" title="Incremental network quantization: towards lossless cnns with low-precision weights" class="ltx_ref">39</a>, <a href="#bib.bib41" title="Towards the limit of network quantization" class="ltx_ref">2</a>]</cite>, teacher-student knowledge distillation <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib42" title="Distilling the knowledge in a neural network" class="ltx_ref">13</a>]</cite>,
etc.</p>
</div>
<div id="S2.p2" class="ltx_para">
<p class="ltx_p">On the other end, in the activation domain, sparsity was also explored in various forms. Rectified
linear unit (ReLU) activations contain more than 50% zero’s on average and speed-up can be realized
on both hardware <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib44" title="Cnvlutin2: ineffectual-activation-and-weight-free deep neural network computing" class="ltx_ref">19</a>]</cite> and algorithmic level <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib9" title="Speeding up convolutional neural networks by exploiting the sparsity of rectifier units" class="ltx_ref">30</a>]</cite>. Activation sparsity can
also be produced from a sparse multiplicative gating module <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib48" title="More is less: a more complicated network with less inference complexity" class="ltx_ref">3</a>]</cite>. In applications such
as 3D object classification, prior work also exploits structures in the sparse input patterns.
OctNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="OctNet: learning deep 3d representations at high resolutions" class="ltx_ref">29</a>]</cite> introduces novel sparse high-resolution 3D representation for 3D
object recognition. Different from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="OctNet: learning deep 3d representations at high resolutions" class="ltx_ref">29</a>]</cite>, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="Submanifold sparse convolutional networks" class="ltx_ref">9</a>]</cite> proposes a
generic valid sparse convolution operator where the input density mask is applied everywhere in the
network. As we will discuss later, while <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="Submanifold sparse convolutional networks" class="ltx_ref">9</a>]</cite> implements a generic convolution
operator, it is not suitable for moderately large input sizes.</p>
</div>
<div id="S2.p3" class="ltx_para">
<p class="ltx_p">When the inputs contain no structured sparsity, one can obtain dynamic computation masks during the
inference process over hundreds of layers. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib12" title="Spatially adaptive computation time for residual networks" class="ltx_ref">4</a>]</cite> learns to skip an adaptive
number of layers in ResNet for unimportant regions in object classification tasks. Similarly,
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib23" title="Not all pixels are equal: difficulty-aware semantic segmentation via deep layer cascade" class="ltx_ref">25</a>]</cite> infers a pixel-wise mask for reweighting the computation in the context of
semantic segmentation. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib38" title="RON: reverse connection with objectness prior networks for object detection" class="ltx_ref">20</a>]</cite> predicts objectness prior heat maps during network inference for
more accurate object detection, but the heat maps do not help speed-up the inference process;
instead, the authors resort to downsampled inputs for faster inference. Given the vast availability
of those computation masks and heat maps during inference, our proposed sparse convolution operators
can be jointly applied to achieve major speedup gains on full resolution.</p>
</div>
<div id="S2.p4" class="ltx_para">
<p class="ltx_p">Sparse inference is beneficial to accuracy as the network focuses more of its computational
attention on useful activation patterns and ignores more of the background noise. For instance,
sparse batch normalization (BN) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib19" title="Batch normalization: accelerating deep network training by reducing internal covariate shift" class="ltx_ref">15</a>, <a href="#bib.bib7" title="Sparsity invariant cnns" class="ltx_ref">31</a>]</cite> is invariant to input sparsity
level and outperforms regular BN in optical flow tasks. Here, we exploit the benefit of sparse BN
within our sparse residual units. Sparse convolution can also help increase the receptive field and
achieve better classification accuracy through perforated operations
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib10" title="PerforatedCNNs: acceleration through elimination of redundant convolutions" class="ltx_ref">5</a>]</cite>.</p>
</div>
<div id="S2.p5" class="ltx_para">
<p class="ltx_p">Sparse computation masks are also related to the attention mechanism. Prior work applied visual
attention on convolutional features and obtained better model interpretability and accuracy on tasks
such as image captioning <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib18" title="Show, attend and tell: neural image caption generation with visual attention" class="ltx_ref">35</a>]</cite>, visual question answering <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib4" title="Stacked attention networks for image question answering" class="ltx_ref">36</a>, <a href="#bib.bib5" title="Hierarchical question-image co-attention for visual question answering" class="ltx_ref">28</a>]</cite>, etc.
However, unlike human attention which helps us reason visual scenes faster, these attentional
network structures do not speed up the inference process since the attention weights are dense
across the receptive field. Instead, we consider the simple case where the attention weights are
binary and explore the speed-up aspect of the attention mechanism in deep neural networks.
</p>
</div>
<section id="S2.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Comparison with <span class="ltx_text ltx_font_italic">im2col</span> based sparse convolution algorithms</h4>

<div id="S2.SS0.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p">Here we discuss the
main differences of our approach compared to popular sparse convolution algorithms based on matrix
lowering, as seen in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib3" title="Sparse convolutional neural networks" class="ltx_ref">27</a>, <a href="#bib.bib9" title="Speeding up convolutional neural networks by exploiting the sparsity of rectifier units" class="ltx_ref">30</a>, <a href="#bib.bib48" title="More is less: a more complicated network with less inference complexity" class="ltx_ref">3</a>]</cite>. These methods all use the same
type of matrix lowering which we refer as <span class="ltx_text ltx_font_italic">im2col</span>. Widely known in the implementation of
dense convolution in Caffe <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib15" title="Caffe: convolutional architecture for fast feature embedding" class="ltx_ref">18</a>]</cite>, <span class="ltx_text ltx_font_italic">im2col</span> gathers sliding windows of shape <span id="S2.SS0.SSS0.Px1.p1.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="k_{H}\times k_{W}\times C"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;">H</span></span></span></span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span></span></span></span></span>, where <span id="S2.SS0.SSS0.Px1.p1.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="k_{H}\times k_{W}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;">H</span></span></span></span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span></span></span></span></span></span> is the filter window size and <span id="S2.SS0.SSS0.Px1.p1.m3" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="C"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span></span></span></span></span> is the input channel
count. <span id="S2.SS0.SSS0.Px1.p1.m4" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="B"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">B</span></span></span></span></span></span></span> active windows are then reshaped into rows of a matrix of shape <span id="S2.SS0.SSS0.Px1.p1.m5" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="B\times(k_{H}\times k_{W}\times C)"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">B</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;">H</span></span></span></span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span></span></span></span></span></span> multiplied with a lowered filter matrix with shape <span id="S2.SS0.SSS0.Px1.p1.m6" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="(k_{H}\times k_{W}\times C)\times K"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">(</span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;">H</span></span></span></span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">)</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;">K</span></span></span></span></span></span></span>, where <span id="S2.SS0.SSS0.Px1.p1.m7" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="K"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.04em;">K</span></span></span></span></span></span></span> is the number of filters. This method is often faster than sparse matrix-vector
product due to contiguous memory access and better parallelism. However, these methods introduce
memory overhead and cannot leverage the benefits of Winograd convolution
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="Arithmetic complexity of computations" class="ltx_ref">33</a>, <a href="#bib.bib24" title="Fast algorithms for convolutional neural networks" class="ltx_ref">22</a>]</cite>. Further, writing out the intermediate lowered results introduces
additional memory bandwidth overhead. <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="Submanifold sparse convolutional networks" class="ltx_ref">9</a>]</cite> designed a look-up table based data
structure for storing sparsity, but it is still slower compared to highly optimized Winograd
convolution. Our approach differs from <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="Submanifold sparse convolutional networks" class="ltx_ref">9</a>, <a href="#bib.bib23" title="Not all pixels are equal: difficulty-aware semantic segmentation via deep layer cascade" class="ltx_ref">25</a>, <a href="#bib.bib9" title="Speeding up convolutional neural networks by exploiting the sparsity of rectifier units" class="ltx_ref">30</a>]</cite> in
that we gather block-wise slices from tensors and maintain the tensor shape instead of lowering them
to vectors. Within each active block, we perform a <span class="ltx_text ltx_font_italic">regular</span> dense convolution and build on
top of a <span id="S2.SS0.SSS0.Px1.p1.m8" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="2-3\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span><span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span> speedup from using Winograd convolution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib25" title="Arithmetic complexity of computations" class="ltx_ref">33</a>, <a href="#bib.bib24" title="Fast algorithms for convolutional neural networks" class="ltx_ref">22</a>]</cite>
compared to general matrix-matrix multiplication (GEMM).

</p>
</div>
</section>
</section>
<section id="S3" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">3 </span>SBNet: Sparse Blocks Network</h2>

<div id="S3.p1" class="ltx_para">
<p class="ltx_p">In this paper, we show that block sparsity can be exploited to significantly reduce the computational
complexity of convolutional layers in deep neural networks. Unlike previous work taking advantage of
unstructured sparsity, we show that our approach results in both theoretical and practical speed-up
without loss of accuracy. We observe that many input sources have structured sparsity that meshes
well with block sparsity - background pixels are likely to be surrounded by other background pixels.
It stands to reason that computations for entire spatial clumps or “blocks” of activations can be
skipped.</p>
</div>
<div id="S3.p2" class="ltx_para">
<p class="ltx_p">Block sparsity is defined in terms of a mask that can be known upfront from the input data domain
knowledge and <span class="ltx_text ltx_font_italic">a priori</span> sparsity structure, or can be computed using lower cost operations. In
particular, we show the usefulness of our convolution algorithm on LiDAR object detection and we
exploit the sparsity from the road and sidewalk map mask as well as the model predicted foreground mask
at lower-resolution. For speed-up purposes, the same sparsity mask is reused for every layer in our
experiments, but it can also be computed from a different source per layer. In particular, at
different spatial scales within the network, we also use reduced spatial block sizes to better match
the granularity of spatial activations at that scale.</p>
</div>
<div id="S3.p3" class="ltx_para">
<p class="ltx_p">The input to our sparse convolution module is a dense binary mask. Just like other standard sparse
operations, we first need to extract a list of active location indices, which is named the
<span class="ltx_text ltx_font_italic">reduce mask</span> operation. Then, we would like to extract data from the sparse inputs at
specified locations and paste the computed results back to the original tensor. To summarize, there
are two major building blocks in our approach to sparse block-wise convolution:</p>
</div>
<div id="S3.p4" class="ltx_para">
<ol id="S3.I1" class="ltx_enumerate">
<li id="S3.I1.i1" class="ltx_item">
<div id="S3.I1.i1.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Reduce mask to indices</span>: converts a binary mask to a list of indices, where each
index references the location of the corresponding <span id="S3.I1.i1.p1.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span>-dimensional block in the input tensor and in
our current implementation this is a 3-<span id="S3.I1.i1.p1.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="d"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span> tuple (batch <span id="S3.I1.i1.p1.m3" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span>, <span id="S3.I1.i1.p1.m4" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span>-location, <span id="S3.I1.i1.p1.m5" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>-location) shared
across the channel dimension (see Figure&nbsp;<a href="#S3.F2" title="Figure 2 ‣ 3 SBNet: Sparse Blocks Network ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>).</p>
</div>
</li>
<li id="S3.I1.i2" class="ltx_item">
<div id="S3.I1.i2.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_bold">Sparse gather/scatter</span>: For gathering, we extract a block from the input
tensor, given the start location and the size of the <span id="S3.I1.i2.p1.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span>-d block. Scatter is the inverse operation
where we update the output tensor using previously gathered and transformed data.</p>
</div>
</li>
</ol>
</div>
<div id="S3.p5" class="ltx_para">
<p class="ltx_p">In this section, we first go over details of the above two building blocks, and then we introduce
a sparse blocks residual unit which groups several layers of computation into sparse blocks. Then
follows implementation details that are crucial to achieving a practical speed-up.</p>
</div>
<figure id="S3.F2" class="ltx_figure"><img src="figures/reduce_mask_fig.png" id="S3.F2.g1" class="ltx_graphics ltx_centering" width="540" height="337" alt="Rectangular tiling for converting dense binary mask into sparse locations.">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 2: </span>Rectangular tiling for converting dense binary mask into sparse locations.</figcaption>
</figure>
<section id="S3.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.1 </span>Reduce mask to indices</h3>

<div id="S3.SS1.p1" class="ltx_para">
<p class="ltx_p">We start with a feature map of size <span id="S3.SS1.p1.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="H\times W\times C"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;">H</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span></span></span></span></span>. We will demonstrate this for the case of
2D convolutions but our approach is applicable to higher dimensions. Let <span id="S3.SS1.p1.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="M\in\{0,1\}^{H\times W}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.081em;">M</span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">∈</span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">{</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">0</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span><span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">}</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;">H</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span></span></span></span></span></span> be the binary mask representing the sparsity pattern. We would like to take advantage of
non-sparse convolution operations as they have been heavily optimized. With this in mind, we propose
to cover the non-zero locations with a set of rectangles. Unfortunately, covering any binary shape
with a minimal number of rectangles is an NP-complete problem <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib26" title="Optiml rectangle covers for convex rectilinear polygons" class="ltx_ref">6</a>]</cite>.
Furthermore, using rectangles of different shapes is hard to balance the computational load of
parallel processors. Therefore, we chose to have a uniform block size, so that the gathered blocks
can be batched together and passed into a single dense convolution operation.</p>
</div>
<div id="S3.SS1.p2" class="ltx_para">
<p class="ltx_p">In signal processing “overlap-add” and “overlap-save” are two standard partitioning schemes for
performing convolutions with very long input signals <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib27" title="Digital signal processing in communication systems" class="ltx_ref">7</a>]</cite>. Our sparse tiling
algorithm is an instantiation of the “overlap-save” algorithm where we gather overlapping blocks,
but during the scatter stage, each thread writes to non-overlapping blocks so that the writes do not
require atomic locking. Knowing the block sizes and overlap sizes, we can perform a simple pooling
operation, such as maximum or average pooling followed by a threshold to downsample the input mask.
The resulting non-zero locations are the spatial block locations that we extract the patches from.
Figure&nbsp;<a href="#S3.F3" title="Figure 3 ‣ 3.1 Reduce mask to indices ‣ 3 SBNet: Sparse Blocks Network ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates our tiling algorithm.</p>
</div>
<figure id="S3.F3" class="ltx_figure"><img src="figures/kernel_strides.png" id="S3.F3.g1" class="ltx_graphics ltx_centering" width="540" height="479" alt="A toy example with block size=">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 3: </span>A toy example with block size=<span id="S3.F3.m5" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="5"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">5</span></span></span></span></span></span></span>, kernel size=<span id="S3.F3.m6" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="3\times 3"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3</span></span></span></span></span></span></span>, kernel strides=<span id="S3.F3.m7" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="2\times 2"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span></span></span></span></span></span>.
Block strides are computed as <span id="S3.F3.m8" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="k-s=3-2=1"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span><span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span><span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">2</span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span><span class="mjx-mn MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span></span></span></span>.</figcaption>
</figure>
</section>
<section id="S3.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.2 </span>Sparse gather/scatter</h3>

<div id="S3.SS2.p1" class="ltx_para">
<p class="ltx_p">Sparse gather/scatter operations convert the network between dense and sparse modes. Unlike regular
gather/scatter kernels that are implemented in deep learning libraries (e.g. <span class="ltx_text ltx_font_typewriter">tf.gather_nd,
tf.scatter_nd</span>), our proposed kernels not only operate on dense indices but also expands spatially
to their neighborhood windows. Patch extracting operations (e.g. <span class="ltx_text ltx_font_typewriter">tf.space_to_batch,
tf.batch_to_space</span>) also share some similarities with our approach but lack spatial overlap and
indexing capability. This input overlap is essential to producing the output that seamlessly
stitches the results of adjacent block convolutions in a way that is locally-equivalent to a dense
convolution on a larger block. Here, we introduce the technical details of our proposed gather and
scatter operations.</p>
</div>
<section id="S3.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Gather kernel</h4>

<div id="S3.SS2.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p">Given a list of indices of size <span id="S3.SS2.SSS0.Px1.p1.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="[B,3]"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">[</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">B</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="margin-top: -0.144em; padding-bottom: 0.519em;">,</span></span><span class="mjx-mn MJXc-space1"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.446em; padding-bottom: 0.593em;">]</span></span></span></span></span></span></span>, where <span id="S3.SS2.SSS0.Px1.p1.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="B"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">B</span></span></span></span></span></span></span> is the number of
blocks, each has a tuple of (<span id="S3.SS2.SSS0.Px1.p1.m3" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="n"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">n</span></span></span></span></span></span></span>, <span id="S3.SS2.SSS0.Px1.p1.m4" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="y"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.519em; padding-right: 0.006em;">y</span></span></span></span></span></span></span>, <span id="S3.SS2.SSS0.Px1.p1.m5" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="x"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">x</span></span></span></span></span></span></span>) referencing the center location of the non-sparse
blocks, we then slice the blocks out of the 4-<span id="S3.SS2.SSS0.Px1.p1.m6" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="d"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.003em;">d</span></span></span></span></span></span></span> <span id="S3.SS2.SSS0.Px1.p1.m7" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="N\times H\times W\times C"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;">N</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;">H</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span></span></span></span></span> input tensor using
<span id="S3.SS2.SSS0.Px1.p1.m8" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h\times w\times C"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span></span></span></span></span> slices, where <span id="S3.SS2.SSS0.Px1.p1.m9" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span> and <span id="S3.SS2.SSS0.Px1.p1.m10" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span></span> are the blocks’ height and width, and stack the <span id="S3.SS2.SSS0.Px1.p1.m11" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="B"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">B</span></span></span></span></span></span></span>
slices into a new tensor along the batch dimension, yielding a <span id="S3.SS2.SSS0.Px1.p1.m12" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="B\times h\times w\times C"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">B</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span></span></span></span></span> tensor.</p>
</div>
</section>
<section id="S3.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Scatter kernel</h4>

<div id="S3.SS2.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p">Scatter is an operation inverse to gather, reusing the same input mask
and block index list. The input to scatter kernel is a tensor of shape <span id="S3.SS2.SSS0.Px2.p1.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="B\times h^{\prime}\times w^{\prime}\times C"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">B</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span></span></span></span></span>. For a mini-network shown in Figure&nbsp;<a href="#S1.F1" title="Figure 1 ‣ 1 Introduction ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, <span id="S3.SS2.SSS0.Px2.p1.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h^{\prime}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span></span></span></span></span></span></span></span> and <span id="S3.SS2.SSS0.Px2.p1.m3" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w^{\prime}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span></span></span></span></span></span></span></span> are computed according to the
output size reduction following a single unpadded convolution (also known as valid convolution).
This convolution is slotted between the scatter and gather operations. When this convolution has a
kernel size of <span id="S3.SS2.SSS0.Px2.p1.m4" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="k_{h}\times k_{w}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span></span></span></span></span></span> and strides <span id="S3.SS2.SSS0.Px2.p1.m5" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="s_{h}\times s_{w}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.219em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-msubsup MJXc-space2"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span></span><span class="mjx-sub" style="font-size: 70.7%; vertical-align: -0.212em; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span></span></span></span></span></span>, then, <span id="S3.SS2.SSS0.Px2.p1.m6" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="h^{\prime}=\frac{h-k_{h}+1}{s_{h}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span><span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 2.74em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 3.875em; top: -1.651em;"><span class="mjx-mrow" style=""><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span><span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.295em; padding-right: 0.06em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span><span class="mjx-denominator" style="font-size: 70.7%; width: 3.875em; bottom: -0.763em;"><span class="mjx-msubsup" style=""><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span></span><span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.295em; padding-right: 0.06em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">h</span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 2.74em;" class="mjx-line"></span></span><span style="height: 1.707em; vertical-align: -0.54em;" class="mjx-vsize"></span></span></span></span></span></span></span>, and
<span id="S3.SS2.SSS0.Px2.p1.m7" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w^{\prime}=\frac{w-k_{w}+1}{s_{w}}"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span><span class="mjx-sup" style="font-size: 70.7%; vertical-align: 0.513em; padding-left: 0px; padding-right: 0.071em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.298em;">′</span></span></span></span></span></span><span class="mjx-mo MJXc-space3"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.077em; padding-bottom: 0.298em;">=</span></span><span class="mjx-mfrac MJXc-space3"><span class="mjx-box MJXc-stacked" style="width: 2.921em; padding: 0px 0.12em;"><span class="mjx-numerator" style="font-size: 70.7%; width: 4.131em; top: -1.555em;"><span class="mjx-mrow" style=""><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">−</span></span><span class="mjx-msubsup"><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">k</span></span></span><span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.18em; padding-right: 0.06em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.298em; padding-bottom: 0.446em;">+</span></span><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1</span></span></span></span><span class="mjx-denominator" style="font-size: 70.7%; width: 4.131em; bottom: -0.668em;"><span class="mjx-msubsup" style=""><span class="mjx-base"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">s</span></span></span><span class="mjx-sub" style="font-size: 83.3%; vertical-align: -0.18em; padding-right: 0.06em;"><span class="mjx-texatom" style=""><span class="mjx-mrow"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span></span><span style="border-bottom: 1.3px solid; top: -0.296em; width: 2.921em;" class="mjx-line"></span></span><span style="height: 1.572em; vertical-align: -0.472em;" class="mjx-vsize"></span></span></span></span></span></span></span>. Figure&nbsp;<a href="#S3.F3" title="Figure 3 ‣ 3.1 Reduce mask to indices ‣ 3 SBNet: Sparse Blocks Network ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a> illustrates a toy example how the output
sizes are calculated.</p>
</div>
<figure id="S3.F4" class="ltx_figure"><img src="figures/sparse_residual_fig2.png" id="S3.F4.g1" class="ltx_graphics ltx_centering" width="540" height="625" alt="A residual unit can be grouped into a sparse unit sharing one gather and scatter.">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 4: </span>A residual unit can be grouped into a sparse unit sharing one gather and scatter.</figcaption>
</figure>
</section>
</section>
<section id="S3.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.3 </span>Sparse residual units</h3>

<div id="S3.SS3.p1" class="ltx_para">
<p class="ltx_p">The ResNet architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="Deep residual learning for image recognition" class="ltx_ref">11</a>]</cite> is widely used in many
state-of-the-art deep networks. Sparse residual units were previously explored using Valid Sparse
Convolution proposed in <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="Submanifold sparse convolutional networks" class="ltx_ref">9</a>]</cite>. Our proposed sparse blocks convolution also
integrates well with residual units. A single residual unit contains three convolutions, batch
normalization, and ReLU layers, all of which can be operated in sparse mode. The total increase in
receptive field of a residual unit is the same as a single <span id="S3.SS3.p1.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="3\times 3"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3</span></span></span></span></span></span></span> convolution. Therefore, all 9
layers can share a single pair of gathering and scattering operations without growing the overlap
area between blocks. In addition to the computation savings, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib7" title="Sparsity invariant cnns" class="ltx_ref">31</a>]</cite> showed that
batch-normalizing across non-sparse elements contributes to better model accuracy since it ignores
non-valid data that may introduce noise to the statistics. Figure&nbsp;<a href="#S3.F4" title="Figure 4 ‣ Scatter kernel ‣ 3.2 Sparse gather/scatter ‣ 3 SBNet: Sparse Blocks Network ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a> shows a
computation graph of our sparse version of the residual unit.</p>
</div>
<section id="S3.SS3.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">End-to-end training of SBNet</h4>

<div id="S3.SS3.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p">is required since batch normalization (BN) statistics are
different between full-scale activations and dense-only activations. The gradient of a scatter
operation is simply the gather operation vice versa. When calculating the gradients of our
overlapping gather operation, the scatter needs to perform atomic addition of gradients on the edges
of overlapping tiles.</p>
</div>
</section>
</section>
<section id="S3.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">3.4 </span>Implementation details</h3>

<div id="S3.SS4.p1" class="ltx_para">
<p class="ltx_p">One of the major contributions of this work is an implementation of our block convolution algorithm
using custom CUDA kernels. As we will show in our experiments, this results in a significant
speed-up in terms of wall-clock time. This contrasts the literature, where only theoretical gains
are reported <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="Submanifold sparse convolutional networks" class="ltx_ref">9</a>]</cite>. In this section, we detail the techniques necessary to
achieve such speed-ups in practice.</p>
</div>
<section id="S3.SS4.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Fused downsample and indexing kernel</h4>

<div id="S3.SS4.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p">To minimize the intermediate outputs between
kernels, we fused the downsample and indexing kernels into one. Inside each tile, we compute a fused
max or average pooling operation followed by writing out the block index into a sequential index
array using GPU atomics to increment the block counter. Thus the input is a <span id="S3.SS4.SSS0.Px1.p1.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="N\times H\times W"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;">N</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;">H</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span></span>
tensor and the output is a list of <span id="S3.SS4.SSS0.Px1.p1.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="B\times 3"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em;">B</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3</span></span></span></span></span></span></span> sparse indices referring to full channel slices
within each block.</p>
</div>
</section>
<section id="S3.SS4.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Fused transpose+gather and transpose+scatter kernels</h4>

<div id="S3.SS4.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p">When performing 2D spatial gather
and scatter, we favor <span id="S3.SS4.SSS0.Px2.p1.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="NHWC"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;">N</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;">H</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span></span></span></span></span> format because of channel memory locality: in <span id="S3.SS4.SSS0.Px2.p1.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="NHWC"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;">N</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;">H</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span></span></span></span></span> format, every
memory strip of size <span id="S3.SS4.SSS0.Px2.p1.m3" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w\times C"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mi MJXc-space2"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span></span></span></span></span> is contiguous, whereas in <span id="S3.SS4.SSS0.Px2.p1.m4" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="NCHW"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;">N</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;">H</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span></span> format, only strips of size <span id="S3.SS4.SSS0.Px2.p1.m5" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="w"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em;">w</span></span></span></span></span></span></span>
are contiguous. Because cuDNN library runs faster with <span id="S3.SS4.SSS0.Px2.p1.m6" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="NCHW"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;">N</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;">H</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span></span> data layout for convolutions and batch
normalization, our gather/scatter kernel also fuses the transpose from <span id="S3.SS4.SSS0.Px2.p1.m7" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="NHWC"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;">N</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;">H</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span></span></span></span></span> to <span id="S3.SS4.SSS0.Px2.p1.m8" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="NCHW"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;">N</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;">H</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span></span> tensor data
layout inside the same CUDA kernel. This saves a memory round-trip from doing additional transpose
operations and is instrumental in achieving a practical speed-up.
</p>
</div>
</section>
<section id="S3.SS4.SSS0.Px3" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Fused scatter-add kernel for residual blocks</h4>

<div id="S3.SS4.SSS0.Px3.p1" class="ltx_para">
<p class="ltx_p">For ResNet architecture during inference,
the input tensor can be reused for output so that an extra memory allocation is avoided and there is
no need to wipe the output tensor to be all zeros. We implemented a fused kernel of 2D scatter and
addition, where we only update the non-sparse locations by adding the convolution results back to
the input tensor.

</p>
</div>
</section>
</section>
</section>
<section id="S4" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">4 </span>Experiments</h2>

<div id="S4.p1" class="ltx_para">
<p class="ltx_p">We validate our sparse blocks networks on our LiDAR 3D bird’s eye view (BEV) detection benchmark
where the computation mask is available through offline road and sidewalk map information. In
addition to using a static map-based mask, we also explored using dynamic attention masks with
higher sparsity predicted by a small foreground segmentation network pretrained on dense box labels.
We investigate two key aspects of our proposed model: 1) inference speed-up compared to a dense deep
CNN detector; 2) change in detection accuracy brought by the use of sparse convolution.</p>
</div>
<section id="S4.SS0.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Experiment environments</h4>

<div id="S4.SS0.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p">For all of the experiments, we implemented and benchmarked in
TensorFlow 1.2.1 using cuDNN 6.0. Because TensorFlow by default uses <span id="S4.SS0.SSS0.Px1.p1.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="NHWC"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;">N</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;">H</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span></span></span></span></span></span> tensor format it incurs a
lot of overhead
compared to cuDNN’s preferred <span id="S4.SS0.SSS0.Px1.p1.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="NCHW"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;">N</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;">H</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span></span> format,
we also implemented standard ResNet blocks in <span id="S4.SS0.SSS0.Px1.p1.m3" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="NCHW"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.085em;">N</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.519em; padding-bottom: 0.298em; padding-right: 0.045em;">C</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.057em;">H</span></span><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.446em; padding-bottom: 0.298em; padding-right: 0.104em;">W</span></span></span></span></span></span></span> for a fair comparison.
To compare with the sub-manifold sparse convolution <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="Submanifold sparse convolutional networks" class="ltx_ref">9</a>]</cite>, we benchmark using
their released PyTorch implementation, using the same version of the cuDNN library. We use NVIDIA
GTX 1080Ti for the layerwise benchmark, and NVIDIA Titan XP for the full network benchmark.
</p>
</div>
</section>
<section id="S4.SS0.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Choosing the optimal block sizes</h4>

<div id="S4.SS0.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p">Smaller block sizes produce higher mask matching
granularity at the expense of increased boundary overlap. Larger blocks have a lower percentage of
overlap, but depending on the feature map resolution, they are less usable due to their relative
size to the total size of the feature map. To achieve the maximum speed-up we perform a search sweep
over a range of block sizes to automatically pick the fastest-performing block decomposition.</p>
</div>
</section>
<section id="S4.SS1" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.1 </span>Datasets</h3>

<div id="S4.SS1.p1" class="ltx_para">
<p class="ltx_p">We used the following datasets for evaluating our LiDAR BEV detectors.</p>
</div>
<section id="S4.SS1.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Tor4d</h4>

<div id="S4.SS1.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p">Our internal TOR4D LiDAR detection dataset consists of 1,239,437 training frames, 5,979 validation
frames and 11,969 test frames. It also contains offline road map information, which can be directly
served as the computation mask without additional processing. Each frame contains LiDAR point cloud
sparse data for a region of 80m<span id="S4.SS1.SSS0.Px1.p1.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>140.8m, with height ranging from -2m to 4m. We use
discretization bin size 0.1m<span id="S4.SS1.SSS0.Px1.p1.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>0.1m<span id="S4.SS1.SSS0.Px1.p1.m3" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>0.2m. Two extra bins on the <span id="S4.SS1.SSS0.Px1.p1.m4" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span>-dimension are
designated to points outside the height range limits and one additional channel is used to encode
the LiDAR intensity. The input tensor of the detector is of size 800<span id="S4.SS1.SSS0.Px1.p1.m5" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>1408<span id="S4.SS1.SSS0.Px1.p1.m6" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>33. Each
frame has a corresponding crop of the road map, which is a top-down binary mask indicating which
pixels belong to the road (see Figure&nbsp;<a href="#S4.F5" title="Figure 5 ‣ KITTI ‣ 4.1 Datasets ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a>).</p>
</div>
</section>
<section id="S4.SS1.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Kitti</h4>

<div id="S4.SS1.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p">To compare with other published methods, we also run experiments on the KITTI 2017 BEV benchmark
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib49" title="Are we ready for autonomous driving? the kitti vision benchmark suite" class="ltx_ref">8</a>]</cite>. The dataset consists of 7,481 training frames and 7,518 test frames. Each frame
contains a region of 80m<span id="S4.SS1.SSS0.Px2.p1.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>70.4m, with height ranging from -3 to 1 m. We use discretization bin
size 0.1m<span id="S4.SS1.SSS0.Px2.p1.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>0.1m<span id="S4.SS1.SSS0.Px2.p1.m3" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>0.2m. Two extra bins on the <span id="S4.SS1.SSS0.Px2.p1.m4" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="z"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mi"><span class="mjx-char MJXc-TeX-math-I" style="padding-top: 0.225em; padding-bottom: 0.298em; padding-right: 0.003em;">z</span></span></span></span></span></span></span>-dimension are designated to points
outside the height range limits and one additional channel is used to encode the LiDAR intensity.
The input tensor of the detector is of size 800<span id="S4.SS1.SSS0.Px2.p1.m5" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>704<span id="S4.SS1.SSS0.Px2.p1.m6" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>23.</p>
</div>
<figure id="S4.F5" class="ltx_figure"><img src="x1.png" id="S4.F5.g1" class="ltx_graphics ltx_centering" width="810" height="460" alt="An example frame from our TOR4D LiDAR detection dataset. A single sweep over a region of
80m ">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 5: </span>An example frame from our TOR4D LiDAR detection dataset. A single sweep over a region of
80m <span id="S4.F5.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span> 140.8m with a bird’s eye view. The road map is colored in blue, and ground-truth
detections are shown in green bounding boxes.</figcaption>
</figure>
</section>
</section>
<section id="S4.SS2" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.2 </span>Model</h3>

<section id="S4.SS2.SSS0.Px1" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">3D object detector network</h4>

<div id="S4.SS2.SSS0.Px1.p1" class="ltx_para">
<p class="ltx_p">We adopt a fully convolutional detector architecture that
resembles <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib32" title="Focal loss for dense object detection" class="ltx_ref">26</a>]</cite>. Our model has a residual network backbone and one convolutional and two
upsampling layers with skip connections. For the residual backbone part, it has 2 initial
convolution layers (conv-1), followed by [3, 6, 6, 3] residual units per residual block (conv-2 -
conv-5), with channel depth [96, 192, 256, 384], and 16<span id="S4.SS2.SSS0.Px1.p1.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span> downsampled activation size at the
top of the backbone network. Two extra upsampling (deconvolution) layers are appended to bring the
outputs back to 4<span id="S4.SS2.SSS0.Px1.p1.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span> downsampled size, with skip connections from the outputs of conv-4 and
conv-3. Three branches of the outputs predict object classes, box sizes and orientations
respectively. Our sparse residual blocks and sparse convolutions are applied on all layers.</p>
</div>
</section>
<section id="S4.SS2.SSS0.Px2" class="ltx_paragraph">
<h4 class="ltx_title ltx_title_paragraph">Foreground mask network</h4>

<div id="S4.SS2.SSS0.Px2.p1" class="ltx_para">
<p class="ltx_p">To predict foreground computation masks, we adopt a Pyramid
Scene Parsing Network (PSPNet) <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib36" title="Pyramid scene parsing network" class="ltx_ref">38</a>]</cite> on a ResNet-18 architecture <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib34" title="Deep residual learning for image recognition" class="ltx_ref">11</a>]</cite> at 8<span id="S4.SS2.SSS0.Px2.p1.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
downsampled input resolution. The network has no bottleneck layers and has one initial convolution
layer, followed by [2, 2, 2, 2] residual units per residual blocks, with channel depth [32, 64, 128,
256]. The network is trained to predict dilated dense box pixel labels.</p>
</div>
</section>
</section>
<section id="S4.SS3" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.3 </span>Experimental design</h3>

<div id="S4.SS3.p1" class="ltx_para">
<p class="ltx_p">We first run standalone layerwise speed-up tests, and we compare our approach with the theoretical
speed-up, i.e. 1/(1-sparsity), and the released implementation of sub-manifold sparse CNN
<cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="Submanifold sparse convolutional networks" class="ltx_ref">9</a>]</cite> (“Sub-M”). Using the same activation size of our detector network, we
test the speed-up on three types of masks:</p>
<ol id="S4.I1" class="ltx_enumerate">
<li id="S4.I1.i1" class="ltx_item">
<div id="S4.I1.i1.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Synthetic</span> masks generated using the top-left sub-region of input images to measure
the practical upper bound on speed-up.</p>
</div>
</li>
<li id="S4.I1.i2" class="ltx_item">
<div id="S4.I1.i2.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Road map</span> masks obtained from our offline map data in TOR4D.
</p>
</div>
</li>
<li id="S4.I1.i3" class="ltx_item">
<div id="S4.I1.i3.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Predicted</span> masks obtained from the outputs of PSPNet.</p>
</div>
</li>
</ol>
<p class="ltx_p">We compare detection accuracy with two baselines:</p>
<ol id="S4.I2" class="ltx_enumerate">
<li id="S4.I2.i1" class="ltx_item">
<div id="S4.I2.i1.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Dense</span>: a dense network trained on all detection groundtruth.</p>
</div>
</li>
<li id="S4.I2.i2" class="ltx_item">
<div id="S4.I2.i2.p1" class="ltx_para">
<p class="ltx_p"><span class="ltx_text ltx_font_italic">Dense w/ Road Mask</span>: a dense network trained on detection groundtruth within the road
mask, i.e. treating regions outside the road as the ignore region.</p>
</div>
</li>
</ol>
<p class="ltx_p">Our SBNets use computation masks from road and sidewalk maps and predicted masks, trained end-to-end
with the same number of training steps as the dense baselines.
Detection accuracy is evaluated with on-road vehicles only.</p>
</div>
<figure id="S4.F6" class="ltx_figure"><img src="x2.png" id="S4.F6.g1" class="ltx_graphics ltx_centering" width="928" height="181" alt="
Residual block speed-up at resolution ">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 6: </span>
Residual block speed-up at resolution <span id="S4.F6.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="400\times 704"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">400</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">704</span></span></span></span></span></span></span> (conv-2) for a range of sparsity level using
synthetic, road map, and predicted masks. Road masks do not have a full range of sparsity because
the dataset is collected on the road.</figcaption>
</figure>
<figure id="S4.T1" class="ltx_table">

<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Stage</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Size</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">Sub-M (</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib6" title="Submanifold sparse convolutional networks" class="ltx_ref">9</a><span class="ltx_text" style="font-size:90%;">]</span></cite><span class="ltx_text" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">SBNet (Ours)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">conv-2</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">400</span><span id="S4.T1.m3" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">704</span><span id="S4.T1.m4" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">24</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">0.40</span><span id="S4.T1.m5" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">3.39</span><span id="S4.T1.m6" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:90%;">conv-3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">200</span><span id="S4.T1.m7" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">352</span><span id="S4.T1.m8" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">48</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">0.75</span><span id="S4.T1.m9" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">2.47</span><span id="S4.T1.m10" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:90%;">conv-4</span></td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">100</span><span id="S4.T1.m11" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">176</span><span id="S4.T1.m12" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">64</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">0.28</span><span id="S4.T1.m13" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">1.34</span><span id="S4.T1.m14" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:90%;">conv-5</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<span class="ltx_text" style="font-size:90%;">50</span><span id="S4.T1.m15" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">88</span><span id="S4.T1.m16" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">96</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<span class="ltx_text" style="font-size:90%;">0.13</span><span id="S4.T1.m17" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<span class="ltx_text" style="font-size:90%;">0.88</span><span id="S4.T1.m18" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 1: </span>Speed-up of a single <span id="S4.T1.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="3\times 3"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">3</span></span></span></span></span></span></span> convolution on synthetic mask at 90% sparsity. Theoretical
speed-up is 10.</figcaption></figure>
<figure id="S4.T2" class="ltx_table">

<div class="ltx_block ltx_align_center" style="width:496.9pt;vertical-align:-0.0pt;">
<table class="ltx_tabular ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Stage</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">#Units</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Size</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">Sub-M (</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib6" title="Submanifold sparse convolutional networks" class="ltx_ref">9</a><span class="ltx_text" style="font-size:90%;">]</span></cite><span class="ltx_text" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">SBNet (Ours)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">conv-2</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">400</span><span id="S4.T2.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">704</span><span id="S4.T2.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">96</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">0.52</span><span id="S4.T2.m3" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">8.22</span><span id="S4.T2.m4" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:90%;">conv-3</span></th>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text" style="font-size:90%;">6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">200</span><span id="S4.T2.m5" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">352</span><span id="S4.T2.m6" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">192</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">1.65</span><span id="S4.T2.m7" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">6.27</span><span id="S4.T2.m8" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:90%;">conv-4</span></th>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text" style="font-size:90%;">6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">100</span><span id="S4.T2.m9" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">176</span><span id="S4.T2.m10" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">256</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">0.85</span><span id="S4.T2.m11" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">3.73</span><span id="S4.T2.m12" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:90%;">conv-5</span></th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text" style="font-size:90%;">3</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<span class="ltx_text" style="font-size:90%;">50</span><span id="S4.T2.m13" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">88</span><span id="S4.T2.m14" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">384</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<span class="ltx_text" style="font-size:90%;">0.58</span><span id="S4.T2.m15" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<span class="ltx_text" style="font-size:90%;">1.64</span><span id="S4.T2.m16" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
</tr>
</tbody>
</table>
</div>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 2: </span>Speed-up of residual units on synthetic masks at 90% sparsity. Theoretical speed-up is 10.</figcaption></figure>
<figure id="S4.F7" class="ltx_figure"><img src="x3.png" id="S4.F7.g1" class="ltx_graphics ltx_centering" width="540" height="351" alt="
Full detector network speed-ups when using road map and predicted masks. An average speed-up in each
sparsity level is plotted with an error bar representing the standard deviation.">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 7: </span>
Full detector network speed-ups when using road map and predicted masks. An average speed-up in each
sparsity level is plotted with an error bar representing the standard deviation.</figcaption>
</figure>
</section>
<section id="S4.SS4" class="ltx_subsection">
<h3 class="ltx_title ltx_title_subsection">
<span class="ltx_tag ltx_tag_subsection">4.4 </span>Results and Discussion</h3>

<div id="S4.SS4.p1" class="ltx_para">
<p class="ltx_p">Inference speed-ups for single convolution layers and residual blocks are listed in
Table&nbsp;<a href="#S4.T1" title="Table 1 ‣ 4.3 Experimental design ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">1</span></a>, <a href="#S4.T2" title="Table 2 ‣ 4.3 Experimental design ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">2</span></a>, <a href="#S4.T3" title="Table 3 ‣ 4.4 Results and Discussion ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>, <a href="#S4.T4" title="Table 4 ‣ 4.4 Results and Discussion ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>. For single
convolutions, our method achieves over 2 <span id="S4.SS4.p1.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span> speed-up for sparsity at 90% at large
resolutions, whereas for residual units we obtain a significantly higher speed-up by grouping
multiple convolutions, BNs and ReLUs into a single sparse block sharing the sparse gather-transpose
and sparse scatter-transpose computation costs.</p>
</div>
<div id="S4.SS4.p2" class="ltx_para">
<p class="ltx_p">Notably, <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib6" title="Submanifold sparse convolutional networks" class="ltx_ref">9</a>]</cite> is slower than dense convolution on most activation sizes and
sparsity values, whereas our Sparse Blocks achieve much higher speed-up on large resolution sizes,
highlighting the practical contributions of our algorithm as increasing number of real-time
applications involve high-resolution inputs and outputs.</p>
</div>
<div id="S4.SS4.p3" class="ltx_para">
<p class="ltx_p">Figure&nbsp;<a href="#S4.F6" title="Figure 6 ‣ 4.3 Experimental design ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a> plots speed-up vs. sparsity on conv-2 residual blocks, for three types
of different masks: <span class="ltx_text ltx_font_italic">synthetic</span>, <span class="ltx_text ltx_font_italic">road map</span>, and <span class="ltx_text ltx_font_italic">predicted</span>. Road maps and
predicted masks incur extra overhead compared to synthetic masks due to irregular shapes. Our method
significantly closes the gap between real implementations and the theoretical maximum and does not
slow down computation even at lower sparsity ratio such as 50 - 60%, which is the typically the
least sparse road maps in our dataset. The computation masks output from the PSP network are 85 -
90% sparse on average, bringing up the speed-up for all sparse layers (Table&nbsp;<a href="#S4.T3" title="Table 3 ‣ 4.4 Results and Discussion ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">3</span></a>),
compared to using road masks (Table&nbsp;<a href="#S4.T4" title="Table 4 ‣ 4.4 Results and Discussion ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">4</span></a>), which are only 70 - 80% sparse on average.</p>
</div>
<figure id="S4.T3" class="ltx_table">

<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Stage</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">#Units</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Size</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">Sub-M (</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib6" title="Submanifold sparse convolutional networks" class="ltx_ref">9</a><span class="ltx_text" style="font-size:90%;">]</span></cite><span class="ltx_text" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">SBNet (Ours)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">conv-2</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">400</span><span id="S4.T3.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">704</span><span id="S4.T3.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">96</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">0.20</span><span id="S4.T3.m3" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">3.05</span><span id="S4.T3.m4" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:90%;">conv-3</span></th>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text" style="font-size:90%;">6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">200</span><span id="S4.T3.m5" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">352</span><span id="S4.T3.m6" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">192</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">0.37</span><span id="S4.T3.m7" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">2.15</span><span id="S4.T3.m8" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:90%;">conv-4</span></th>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text" style="font-size:90%;">6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">100</span><span id="S4.T3.m9" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">176</span><span id="S4.T3.m10" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">256</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">0.50</span><span id="S4.T3.m11" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">1.65</span><span id="S4.T3.m12" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:90%;">conv-5</span></th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text" style="font-size:90%;">3</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<span class="ltx_text" style="font-size:90%;">50</span><span id="S4.T3.m13" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">88</span><span id="S4.T3.m14" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">384</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<span class="ltx_text" style="font-size:90%;">0.48</span><span id="S4.T3.m15" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<span class="ltx_text" style="font-size:90%;">1.14</span><span id="S4.T3.m16" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 3: </span>Speed-up of residual units on road map masks at average 75% sparsity. Theoretical speed-up
is 4.</figcaption></figure>
<figure id="S4.T4" class="ltx_table">

<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Stage</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">#Units</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Size</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">Sub-M (</span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib6" title="Submanifold sparse convolutional networks" class="ltx_ref">9</a><span class="ltx_text" style="font-size:90%;">]</span></cite><span class="ltx_text" style="font-size:90%;">)</span>
</th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">SBNet (Ours)</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">conv-2</span></th>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">3</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">400</span><span id="S4.T4.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">704</span><span id="S4.T4.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">96</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">0.45</span><span id="S4.T4.m3" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">5.21</span><span id="S4.T4.m4" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:90%;">conv-3</span></th>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text" style="font-size:90%;">6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">200</span><span id="S4.T4.m5" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">352</span><span id="S4.T4.m6" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">192</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">1.36</span><span id="S4.T4.m7" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">3.25</span><span id="S4.T4.m8" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:90%;">conv-4</span></th>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text" style="font-size:90%;">6</span></td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">100</span><span id="S4.T4.m9" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">176</span><span id="S4.T4.m10" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">256</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">0.77</span><span id="S4.T4.m11" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">2.26</span><span id="S4.T4.m12" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_row ltx_border_b ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:90%;">conv-5</span></th>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text" style="font-size:90%;">3</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<span class="ltx_text" style="font-size:90%;">50</span><span id="S4.T4.m13" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">88</span><span id="S4.T4.m14" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;">384</span>
</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<span class="ltx_text" style="font-size:90%;">0.55</span><span id="S4.T4.m15" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r">
<span class="ltx_text" style="font-size:90%;">1.32</span><span id="S4.T4.m16" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 4: </span>Speed-up of residual units on PSPNet predicted masks at average 90% sparsity. Theoretical
speed-up is 10.</figcaption></figure>
<div id="S4.SS4.p4" class="ltx_para">
<p class="ltx_p">Table&nbsp;<a href="#S4.T5" title="Table 5 ‣ 4.4 Results and Discussion ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">5</span></a> reports detection accuracy on the TOR4D test set. We compare the road mask
version of SBNet with a dense baseline that has training loss masked with the road mask for a fair
comparison, since using road masks in the loss function hints learning more important regions. With
a significant 1.8<span id="S4.SS4.p4.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span> speedup, SBNet contributes to another 0.3% gain in AP, suggesting that
sparse convolution and normalization layers during inference can be beneficial dealing with sparse
inputs. When using model predicted computation masks, we are able to reach 2.7<span id="S4.SS4.p4.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span> speedup, with
detection accuracy slightly below our dense baseline.</p>
</div>
<div id="S4.SS4.p5" class="ltx_para">
<p class="ltx_p">Comparison of our approach and other published methods on KITTI can be found in
Table&nbsp;<a href="#S4.T6" title="Table 6 ‣ 4.4 Results and Discussion ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">6</span></a>. The dense detector baseline reached state-of-the-art performance in
“Moderate” and “Hard” settings. The SBNet version of the detector achieves over 2.6<span id="S4.SS4.p5.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
speed-up with almost no loss of accuracy. Including the cost of the mask network, our method is the
fastest among the top performing methods on the KITTI benchmark, an order of magnitude faster than
the published state-of-the-art <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib31" title="Multi-view 3d object detection network for autonomous driving" class="ltx_ref">1</a>]</cite>.</p>
</div>
<div id="S4.SS4.p6" class="ltx_para">
<p class="ltx_p">Detection results of our SBNet detector are visualized in Figure&nbsp;<a href="#S4.F8" title="Figure 8 ‣ 4.4 Results and Discussion ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">8</span></a>. As shown,
PSPNet produces much sparser regions of interest compared to road maps while maintaining relatively
competitive detection accuracy. Many false negative instances have too few LiDAR points and are
difficult to be detected even by a dense detector.</p>
</div>
<div id="S4.SS4.p7" class="ltx_para">
<p class="ltx_p">Finally, we benchmark the computation overhead introduced by PSPNet in
Table&nbsp;<a href="#S4.T7" title="Table 7 ‣ 4.4 Results and Discussion ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">7</span></a>, which spends less than 4% of the time of a full dense pass of the
detector network. SBNet and PSPNet combined together achieve 26.6% relative gain in speed compared
to the Road Map counterpart. In addition to higher sparsity and speed-up, the predicted masks are
much more flexible in areas without offline maps.</p>
</div>
<figure id="S4.F8" class="ltx_figure"><img src="figures/figure_results.png" id="S4.F8.g1" class="ltx_graphics ltx_centering" width="928" height="560" alt="A bird’s eye view of our 3D vehicle detection results. Green boxes denote groundtruth and
orange denote outputs. Blue regions denote sparse computation masks. Visit
">
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_figure">Figure 8: </span>A bird’s eye view of our 3D vehicle detection results. Green boxes denote groundtruth and
orange denote outputs. Blue regions denote sparse computation masks. Visit
<a href="https://eng.uber.com/sbnet" title="" class="ltx_ref ltx_url ltx_font_typewriter">https://eng.uber.com/sbnet</a> for a full video.</figcaption>
</figure>
<figure id="S4.T5" class="ltx_table">

<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Model</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Train Loss</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Sparsity</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Avg. Speed-up</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">AP</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Dense</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Road Mask</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">0%</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">1.0</span><span id="S4.T5.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">75.70</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:90%;">SBNet +Road</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text" style="font-size:90%;">Road Mask</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text" style="font-size:90%;">70%</span></td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span class="ltx_text" style="font-size:90%;">1.78</span><span id="S4.T5.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold" style="font-size:90%;">76.01</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Dense</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">No Mask</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">0%</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">1.0</span><span id="S4.T5.m3" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:90%;">73.28</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:90%;">SBNet +PSP</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text" style="font-size:90%;">PSP Mask</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text" style="font-size:90%;">86%</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_bold" style="font-size:90%;">2.66<span id="S4.T5.m4" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="\times"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span></span></span></span></span></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text" style="font-size:90%;">73.01</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 5: </span>Speed-up &amp; detection accuracy of SBNet on the TOR4D dataset. AP at 70% IoU.</figcaption></figure>
<figure id="S4.T6" class="ltx_table">

<table class="ltx_tabular ltx_centering ltx_align_middle">
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Model</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Moderate</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Easy</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Hard</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Avg. Time</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t">
<span class="ltx_text" style="font-size:90%;">DoBEM </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib46" title="Vehicle detection and localization on bird’s eye view elevation images using convolutional neural network" class="ltx_ref">37</a><span class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">36.95</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">36.49</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">38.10</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">600 ms</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r">
<span class="ltx_text" style="font-size:90%;">3D FCN </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib45" title="3D fully convolutional network for vehicle detection in point cloud" class="ltx_ref">23</a><span class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text" style="font-size:90%;">62.54</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text" style="font-size:90%;">69.94</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text" style="font-size:90%;">55.94</span></td>
<td class="ltx_td ltx_align_center ltx_border_r">
<span id="S4.T6.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label=">"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mo"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.372em;">&gt;</span></span></span></span></span></span></span><span class="ltx_text" style="font-size:90%;"> 5 s</span>
</td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r">
<span class="ltx_text" style="font-size:90%;">MV3D </span><cite class="ltx_cite ltx_citemacro_cite"><span class="ltx_text" style="font-size:90%;">[</span><a href="#bib.bib31" title="Multi-view 3d object detection network for autonomous driving" class="ltx_ref">1</a><span class="ltx_text" style="font-size:90%;">]</span></cite>
</td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text" style="font-size:90%;">77.00</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text ltx_font_bold" style="font-size:90%;">85.82</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text" style="font-size:90%;">68.94</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text" style="font-size:90%;">240 ms</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Dense</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:90%;">77.05</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">81.70</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text ltx_font_bold" style="font-size:90%;">72.95</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">47.3 ms</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:90%;">SBNet</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text" style="font-size:90%;">76.79</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text" style="font-size:90%;">81.90</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text" style="font-size:90%;">71.40</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r"><span class="ltx_text ltx_font_bold" style="font-size:90%;">17.9 ms</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 6: </span>KITTI Bird’s Eye View (BEV) 2017 Benchmark</figcaption></figure>
<figure id="S4.T7" class="ltx_table">

<table class="ltx_tabular ltx_centering ltx_guessed_headers ltx_align_middle">
<thead class="ltx_thead">
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Network</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Resolution</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Time (ms)</span></th>
</tr>
<tr class="ltx_tr">
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">Dense</span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span id="S4.T7.m1" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="800\times 1408"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">800</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1408</span></span></span></span></span></span></span></th>
<th class="ltx_td ltx_align_center ltx_th ltx_th_column ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">88.0</span></th>
</tr>
</thead>
<tbody class="ltx_tbody">
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">SBNet +Road</span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span id="S4.T7.m2" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="800\times 1408"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">800</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1408</span></span></span></span></span></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">49.5</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_l ltx_border_r"><span class="ltx_text" style="font-size:90%;">SBNet +PSP</span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span id="S4.T7.m3" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="800\times 1408"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">800</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">1408</span></span></span></span></span></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_r"><span class="ltx_text" style="font-size:90%;">33.1</span></td>
</tr>
<tr class="ltx_tr">
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_l ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">PSPNet</span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span id="S4.T7.m4" class="ltx_Math"><span class="mjpage"><span class="mjx-chtml"><span class="mjx-math" aria-label="100\times 176"><span class="mjx-mrow" aria-hidden="true"><span class="mjx-mn"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">100</span></span><span class="mjx-mo MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.225em; padding-bottom: 0.298em;">×</span></span><span class="mjx-mn MJXc-space2"><span class="mjx-char MJXc-TeX-main-R" style="padding-top: 0.372em; padding-bottom: 0.372em;">176</span></span></span></span></span></span></span></td>
<td class="ltx_td ltx_align_center ltx_border_b ltx_border_r ltx_border_t"><span class="ltx_text" style="font-size:90%;">3.2</span></td>
</tr>
</tbody>
</table>
<figcaption class="ltx_caption ltx_centering"><span class="ltx_tag ltx_tag_table">Table 7: </span>Mask network computation overhead</figcaption></figure>
</section>
</section>
<section id="S5" class="ltx_section">
<h2 class="ltx_title ltx_title_section">
<span class="ltx_tag ltx_tag_section">5 </span>Conclusion and Future Work</h2>

<div id="S5.p1" class="ltx_para">
<p class="ltx_p">In this work, we introduce the Sparse Blocks network which features fast convolution computation
given a computation mask with structured sparsity. We verified significant wall-clock speed-ups
compared to state-of-the-art dense convolution implementations. In LiDAR 3D detection
experiments, we show both speed-up and improvement in detection accuracy using road map masks, and
even higher speed-up using model predicted masks while trading off a small amount of accuracy. We
expect our proposed algorithm to achieve further speed-up when used jointly with other orthogonal
methods such as weights pruning, model quantization, etc. As future work, sparse blocks can be
extended to a combination of different rectangle shapes (c.f. OctNet <cite class="ltx_cite ltx_citemacro_cite">[<a href="#bib.bib8" title="OctNet: learning deep 3d representations at high resolutions" class="ltx_ref">29</a>]</cite>) to
get fine-grained mask representation, which can speed up inference with multi-scaled reasoning.</p>
</div>
</section>
<section id="bib" class="ltx_bibliography">
<h2 class="ltx_title ltx_title_bibliography" style="font-size:90%;">References</h2>

<ul id="bib.L1" class="ltx_biblist">
<li id="bib.bib31" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[1]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">X. Chen, H. Ma, J. Wan, B. Li, and T. Xia</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Multi-view 3d object detection network for autonomous driving</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS4.p5" title="4.4 Results and Discussion ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.4</span></a>,
<a href="#S4.T6" title="Table 6 ‣ 4.4 Results and Discussion ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table 6</span></a>.
</span>
</li>
<li id="bib.bib41" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[2]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">Y. Choi, M. El-Khamy, and J. Lee</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Towards the limit of network quantization</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the 5th International Conference on Learning Representations (ICLR)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib48" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[3]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">X. Dong, J. Huang, Y. Yang, and S. Yan</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">More is less: a more complicated network with less inference complexity</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS0.SSS0.Px1.p1" title="Comparison with im2col based sparse convolution algorithms ‣ 2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>,
<a href="#S2.p2" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib12" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[4]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. Figurnov, M. D. Collins, Y. Zhu, L. Zhang, J. Huang, D. P. Vetrov, and R. Salakhutdinov</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Spatially adaptive computation time for residual networks</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p2" title="1 Introduction ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§1</span></a>,
<a href="#S2.p3" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib10" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[5]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. Figurnov, A. Ibraimova, D. P. Vetrov, and P. Kohli</span><span class="ltx_text ltx_bib_year"> (2016)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">PerforatedCNNs: acceleration through elimination of redundant convolutions</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Advances in Neural Information Processing Systems (NIPS)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p4" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib26" class="ltx_bibitem ltx_bib_thesis">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[6]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">P. Franklin</span><span class="ltx_text ltx_bib_year"> (1984)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Optiml rectangle covers for convex rectilinear polygons</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_type">Ph.D. Thesis</span>, <span class="ltx_text ltx_bib_publisher">Simon Fraser University</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS1.p1" title="3.1 Reduce mask to indices ‣ 3 SBNet: Sparse Blocks Network ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.1</span></a>.
</span>
</li>
<li id="bib.bib27" class="ltx_bibitem ltx_bib_book">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[7]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. Frerking</span><span class="ltx_text ltx_bib_year"> (1994)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Digital signal processing in communication systems</span>.
</span>
<span class="ltx_bibblock"> <span class="ltx_text ltx_bib_publisher">New York: Van Nostrand Reinhold</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><span class="ltx_text isbn ltx_bib_external">ISBN 0442016166</span></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S3.SS1.p2" title="3.1 Reduce mask to indices ‣ 3 SBNet: Sparse Blocks Network ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.1</span></a>.
</span>
</li>
<li id="bib.bib49" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[8]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Geiger, P. Lenz, and R. Urtasun</span><span class="ltx_text ltx_bib_year"> (2012)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Are we ready for autonomous driving? the kitti vision benchmark suite</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS1.SSS0.Px2.p1" title="KITTI ‣ 4.1 Datasets ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.1</span></a>.
</span>
</li>
<li id="bib.bib6" class="ltx_bibitem ltx_bib_article">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[9]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">B. Graham and L. van der Maaten</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Submanifold sparse convolutional networks</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">CoRR</span> <span class="ltx_text ltx_bib_volume">abs/1706.01307</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://arxiv.org/abs/1706.01307" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS0.SSS0.Px1.p1" title="Comparison with im2col based sparse convolution algorithms ‣ 2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>,
<a href="#S2.p2" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>,
<a href="#S3.SS3.p1" title="3.3 Sparse residual units ‣ 3 SBNet: Sparse Blocks Network ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.3</span></a>,
<a href="#S3.SS4.p1" title="3.4 Implementation details ‣ 3 SBNet: Sparse Blocks Network ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.4</span></a>,
<a href="#S4.SS0.SSS0.Px1.p1" title="Experiment environments ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4</span></a>,
<a href="#S4.SS3.p1" title="4.3 Experimental design ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.3</span></a>,
<a href="#S4.SS4.p2" title="4.4 Results and Discussion ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.4</span></a>,
<a href="#S4.T1" title="Table 1 ‣ 4.3 Experimental design ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table 1</span></a>,
<a href="#S4.T2" title="Table 2 ‣ 4.3 Experimental design ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table 2</span></a>,
<a href="#S4.T3" title="Table 3 ‣ 4.4 Results and Discussion ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table 3</span></a>,
<a href="#S4.T4" title="Table 4 ‣ 4.4 Results and Discussion ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table 4</span></a>.
</span>
</li>
<li id="bib.bib14" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[10]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Han, J. Pool, J. Tran, and W. J. Dally</span><span class="ltx_text ltx_bib_year"> (2015)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Learning both weights and connections for efficient neural networks</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Advances in Neural Information Processing Systems (NIPS)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib34" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[11]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. He, X. Zhang, S. Ren, and J. Sun</span><span class="ltx_text ltx_bib_year"> (2016)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Deep residual learning for image recognition</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§1</span></a>,
<a href="#S1.p4" title="1 Introduction ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§1</span></a>,
<a href="#S3.SS3.p1" title="3.3 Sparse residual units ‣ 3 SBNet: Sparse Blocks Network ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.3</span></a>,
<a href="#S4.SS2.SSS0.Px2.p1" title="Foreground mask network ‣ 4.2 Model ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.2</span></a>.
</span>
</li>
<li id="bib.bib47" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[12]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">Y. He, X. Zhang, and J. Sun</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Channel pruning for accelerating very deep neural networks</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the International Conference on Computer Vision (ICCV)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib42" class="ltx_bibitem ltx_bib_article">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[13]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">G. E. Hinton, O. Vinyals, and J. Dean</span><span class="ltx_text ltx_bib_year"> (2015)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Distilling the knowledge in a neural network</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">CoRR</span> <span class="ltx_text ltx_bib_volume">abs/1503.02531</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib20" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[14]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">Y. Ioannou, D. Robertson, R. Cipolla, and A. Criminisi</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Deep roots: improving cnn efficiency with hierarchical filter groups</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib19" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[15]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Ioffe and C. Szegedy</span><span class="ltx_text ltx_bib_year"> (2015)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Batch normalization: accelerating deep network training by reducing internal covariate shift</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the 32nd International Conference on Machine Learning (ICML)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p4" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib37" class="ltx_bibitem ltx_bib_article">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[16]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">L. Itti, C. Koch, and E. Niebur</span><span class="ltx_text ltx_bib_year"> (1998)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">A model of saliency-based visual attention for rapid scene analysis</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">IEEE Trans. Pattern Anal. Mach. Intell.</span> <span class="ltx_text ltx_bib_volume">20</span> (<span class="ltx_text ltx_bib_number">11</span>), <span class="ltx_text ltx_bib_pages"> pp.&nbsp;1254–1259</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p2" title="1 Introduction ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§1</span></a>.
</span>
</li>
<li id="bib.bib11" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[17]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">M. Jaderberg, A. Vedaldi, and A. Zisserman</span><span class="ltx_text ltx_bib_year"> (2014)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Speeding up convolutional neural networks with low rank expansions</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the British Machine Vision Conference (BMVC)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib15" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[18]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. B. Girshick, S. Guadarrama, and T. Darrell</span><span class="ltx_text ltx_bib_year"> (2014)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Caffe: convolutional architecture for fast feature embedding</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the ACM International Conference on Multimedia</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS0.SSS0.Px1.p1" title="Comparison with im2col based sparse convolution algorithms ‣ 2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib44" class="ltx_bibitem ltx_bib_article">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[19]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">P. Judd, A. D. Lascorz, S. Sharify, and A. Moshovos</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Cnvlutin2: ineffectual-activation-and-weight-free deep neural network computing</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">CoRR</span> <span class="ltx_text ltx_bib_volume">abs/1705.00125</span>.
</span>
<span class="ltx_bibblock">External Links: <span class="ltx_text ltx_bib_links"><a href="http://arxiv.org/abs/1705.00125" title="" class="ltx_ref ltx_bib_external">Link</a></span>
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p2" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib38" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[20]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. Kong, F. Sun, A. Yao, H. Liu, M. Lu, and Y. Chen</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">RON: reverse connection with objectness prior networks for object detection</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p2" title="1 Introduction ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§1</span></a>,
<a href="#S2.p3" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib16" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[21]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Krizhevsky, I. Sutskever, and G. E. Hinton</span><span class="ltx_text ltx_bib_year"> (2012)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">ImageNet classification with deep convolutional neural networks</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Advances in Neural Information Processing Systems (NIPS)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p1" title="1 Introduction ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§1</span></a>.
</span>
</li>
<li id="bib.bib24" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[22]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Lavin and S. Gray</span><span class="ltx_text ltx_bib_year"> (2016)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Fast algorithms for convolutional neural networks</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS0.SSS0.Px1.p1" title="Comparison with im2col based sparse convolution algorithms ‣ 2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib45" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[23]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">B. Li</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">3D fully convolutional network for vehicle detection in point cloud</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.T6" title="Table 6 ‣ 4.4 Results and Discussion ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table 6</span></a>.
</span>
</li>
<li id="bib.bib1" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[24]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">H. Li, A. Kadav, I. Durdanovic, H. Samet, and H. P. Graf</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Pruning filters for efficient convnets</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the 5th International Conference on Learning Representations (ICLR)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib23" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[25]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">X. Li, Z. Liu, P. Luo, C. C. Loy, and X. Tang</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Not all pixels are equal: difficulty-aware semantic segmentation via deep layer cascade</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p2" title="1 Introduction ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§1</span></a>,
<a href="#S2.SS0.SSS0.Px1.p1" title="Comparison with im2col based sparse convolution algorithms ‣ 2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>,
<a href="#S2.p3" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib32" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[26]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">T. Lin, P. Goyal, R. B. Girshick, K. He, and P. Dollár</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Focal loss for dense object detection</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the International Conference on Computer Vision (ICCV)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS2.SSS0.Px1.p1" title="3D object detector network ‣ 4.2 Model ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.2</span></a>.
</span>
</li>
<li id="bib.bib3" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[27]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">B. Liu, M. Wang, H. Foroosh, M. F. Tappen, and M. Pensky</span><span class="ltx_text ltx_bib_year"> (2015)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Sparse convolutional neural networks</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS0.SSS0.Px1.p1" title="Comparison with im2col based sparse convolution algorithms ‣ 2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>,
<a href="#S2.p1" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib5" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[28]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">J. Lu, J. Yang, D. Batra, and D. Parikh</span><span class="ltx_text ltx_bib_year"> (2016)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Hierarchical question-image co-attention for visual question answering</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Advances in Neural Information Processing Systems (NIPS)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p5" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib8" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[29]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">G. Riegler, A. O. Ulusoy, and A. Geiger</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">OctNet: learning deep 3d representations at high resolutions</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p2" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>,
<a href="#S5.p1" title="5 Conclusion and Future Work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§5</span></a>.
</span>
</li>
<li id="bib.bib9" class="ltx_bibitem ltx_bib_article">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[30]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Shi and X. Chu</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Speeding up convolutional neural networks by exploiting the sparsity of rectifier units</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">CoRR</span> <span class="ltx_text ltx_bib_volume">abs/1704.07724</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS0.SSS0.Px1.p1" title="Comparison with im2col based sparse convolution algorithms ‣ 2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>,
<a href="#S2.p2" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib7" class="ltx_bibitem ltx_bib_article">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[31]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">J. Uhrig, N. Schneider, L. Schneider, U. Franke, T. Brox, and A. Geiger</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Sparsity invariant cnns</span>.
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_journal">CoRR</span> <span class="ltx_text ltx_bib_volume">abs/1708.06500</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p4" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>,
<a href="#S3.SS3.p1" title="3.3 Sparse residual units ‣ 3 SBNet: Sparse Blocks Network ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§3.3</span></a>.
</span>
</li>
<li id="bib.bib13" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[32]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">W. Wen, C. Wu, Y. Wang, Y. Chen, and H. Li</span><span class="ltx_text ltx_bib_year"> (2016)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Learning structured sparsity in deep neural networks</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Advances in Neural Information Processing Systems (NIPS)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib25" class="ltx_bibitem ltx_bib_book">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[33]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Winograd</span><span class="ltx_text ltx_bib_year"> (1980)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Arithmetic complexity of computations</span>.
</span>
<span class="ltx_bibblock">Vol. <span class="ltx_text ltx_bib_volume">33</span>,  <span class="ltx_text ltx_bib_publisher">SIAM</span>.
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.SS0.SSS0.Px1.p1" title="Comparison with im2col based sparse convolution algorithms ‣ 2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib39" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[34]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">Z. Wu, S. Song, A. Khosla, F. Yu, L. Zhang, X. Tang, and J. Xiao</span><span class="ltx_text ltx_bib_year"> (2015)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">3D shapenets: A deep representation for volumetric shapes</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S1.p2" title="1 Introduction ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§1</span></a>.
</span>
</li>
<li id="bib.bib18" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[35]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">K. Xu, J. Ba, R. Kiros, K. Cho, A. C. Courville, R. Salakhutdinov, R. S. Zemel, and Y. Bengio</span><span class="ltx_text ltx_bib_year"> (2015)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Show, attend and tell: neural image caption generation with visual attention</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the 32nd International Conference on Machine Learning (ICML)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p5" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib4" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[36]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">Z. Yang, X. He, J. Gao, L. Deng, and A. J. Smola</span><span class="ltx_text ltx_bib_year"> (2016)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Stacked attention networks for image question answering</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p5" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
<li id="bib.bib46" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[37]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">S. Yu, T. Westfechtel, R. Hamada, K. Ohno, and S. Tadokoro</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Vehicle detection and localization on bird’s eye view elevation images using convolutional neural network</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the 2017 IEEE International Symposium on Safety, Security and Rescue Robotics (SSRR)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.T6" title="Table 6 ‣ 4.4 Results and Discussion ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">Table 6</span></a>.
</span>
</li>
<li id="bib.bib36" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[38]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">H. Zhao, J. Shi, X. Qi, X. Wang, and J. Jia</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Pyramid scene parsing network</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S4.SS2.SSS0.Px2.p1" title="Foreground mask network ‣ 4.2 Model ‣ 4 Experiments ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§4.2</span></a>.
</span>
</li>
<li id="bib.bib40" class="ltx_bibitem ltx_bib_inproceedings">
<span class="ltx_tag ltx_bib_key ltx_role_refnum ltx_tag_bibitem">[39]</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_author">A. Zhou, A. Yao, Y. Guo, L. Xu, and Y. Chen</span><span class="ltx_text ltx_bib_year"> (2017)</span>
</span>
<span class="ltx_bibblock"><span class="ltx_text ltx_bib_title">Incremental network quantization: towards lossless cnns with low-precision weights</span>.
</span>
<span class="ltx_bibblock">In <span class="ltx_text ltx_bib_inbook">Proceedings of the 5th International Conference on Learning Representations (ICLR)</span>,
</span>
<span class="ltx_bibblock ltx_bib_cited">Cited by: <a href="#S2.p1" title="2 Related work ‣ SBNet: Sparse Blocks Network for Fast Inference" class="ltx_ref"><span class="ltx_text ltx_ref_tag">§2</span></a>.
</span>
</li>
</ul>
</section>
</article>
</div>
<footer class="ltx_page_footer">
<div class="ltx_page_logo">Generated  by <a href="http://dlmf.nist.gov/LaTeXML/">LaTeXML <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAsAAAAOCAYAAAD5YeaVAAAAAXNSR0IArs4c6QAAAAZiS0dEAP8A/wD/oL2nkwAAAAlwSFlzAAALEwAACxMBAJqcGAAAAAd0SU1FB9wKExQZLWTEaOUAAAAddEVYdENvbW1lbnQAQ3JlYXRlZCB3aXRoIFRoZSBHSU1Q72QlbgAAAdpJREFUKM9tkL+L2nAARz9fPZNCKFapUn8kyI0e4iRHSR1Kb8ng0lJw6FYHFwv2LwhOpcWxTjeUunYqOmqd6hEoRDhtDWdA8ApRYsSUCDHNt5ul13vz4w0vWCgUnnEc975arX6ORqN3VqtVZbfbTQC4uEHANM3jSqXymFI6yWazP2KxWAXAL9zCUa1Wy2tXVxheKA9YNoR8Pt+aTqe4FVVVvz05O6MBhqUIBGk8Hn8HAOVy+T+XLJfLS4ZhTiRJgqIoVBRFIoric47jPnmeB1mW/9rr9ZpSSn3Lsmir1fJZlqWlUonKsvwWwD8ymc/nXwVBeLjf7xEKhdBut9Hr9WgmkyGEkJwsy5eHG5vN5g0AKIoCAEgkEkin0wQAfN9/cXPdheu6P33fBwB4ngcAcByHJpPJl+fn54mD3Gg0NrquXxeLRQAAwzAYj8cwTZPwPH9/sVg8PXweDAauqqr2cDjEer1GJBLBZDJBs9mE4zjwfZ85lAGg2+06hmGgXq+j3+/DsixYlgVN03a9Xu8jgCNCyIegIAgx13Vfd7vdu+FweG8YRkjXdWy329+dTgeSJD3ieZ7RNO0VAXAPwDEAO5VKndi2fWrb9jWl9Esul6PZbDY9Go1OZ7PZ9z/lyuD3OozU2wAAAABJRU5ErkJggg==" alt="[LOGO]"></a>
</div></footer>
</div>


<script src="index.js" type="text/javascript"></script></body></html>